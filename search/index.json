[{"content":"操作记录 首页 menu icon 更新 brand svg source ","date":"2024-01-22T16:04:33+08:00","permalink":"http://blog.heyuhua.com/p/blog-%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%96%B0-%E8%BF%81%E7%A7%BB%E5%88%B0-stack/","title":"blog 主题更新: 迁移到 stack"},{"content":"新年第一个flag: 春节期间《缺氧》能解决气体和液体供应问题。\n本文基于 k8s 近期 release, git: commit 70132b0f130acc0bed193d9ba59dd186f0e634cf (HEAD, tag: v1.17.0)\n前言：寻找可能性 \u0026mdash;- 混编 VM 与 Pod cgroup 想象 k8s 可以同时管理 VM 资源了 如何将 vm 资源的cpu，内存配置抽象成 cgroup 并使用 kubelet CgroupManager 统一管理?\nkubelet 的 Cgroup 管理模型 kubelet 作为 k8s 系统中各个节点的“话事者”，其 ContainerManger 模块包揽了所有的 cgroup 管理工作。 ContainerManager 将 Pod 的 cgroup 模型做了层次分离： container -\u0026gt; Pod -\u0026gt; Qos -\u0026gt; Node。\nNode level 节点层面 主要聚焦于 cgroup 横向分配， 通过隔离不同类型 的 cgroup 进行抽象。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Node Capacity --------------------------- | kube-reserved | |-------------------------| | system-reserved | |-------------------------| | eviction-threshold | |-------------------------| | | | allocatable | | (available for pods) | | | | | --------------------------- 默认情况下 节点粒度的管理 分配了 k8s 服务组件的 cgroup， 系统非内核 进程 cgroup， 还有 pod 资源的 cgroup.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 kubeDeps.ContainerManager, err = cm.NewContainerManager( kubeDeps.Mounter, kubeDeps.CAdvisorInterface, cm.NodeConfig{ RuntimeCgroupsName: s.RuntimeCgroups, // `runtime-cghroups` 配置, 创建和运行容器运行时的 cgroup 的绝对名称 SystemCgroupsName: s.SystemCgroups, // cgroup 的绝对名称，用于所有尚未放置在根目录下某 cgroup 内的非内核进程。空值表示不指定 cgroup。回滚该参数需要重启机器。 KubeletCgroupsName: s.KubeletCgroups, // 用于创建和运行 kubelet 的 cgroup 的绝对名称。 ContainerRuntime: s.ContainerRuntime, CgroupsPerQOS: s.CgroupsPerQOS, // 将 Pod 按照不同的 QOS 优先级进行 cgroup 拆分。 CgroupRoot: s.CgroupRoot, CgroupDriver: s.CgroupDriver, KubeletRootDir: s.RootDirectory, ProtectKernelDefaults: s.ProtectKernelDefaults, NodeAllocatableConfig: cm.NodeAllocatableConfig{ // 节点可分配 resource 计算结构体 KubeReservedCgroupName: s.KubeReservedCgroup, // k8s 自身服务 所在 cgroup SystemReservedCgroupName: s.SystemReservedCgroup, // 操作系统非内核进程外的其他进程所在cgroup EnforceNodeAllocatable: sets.NewString(s.EnforceNodeAllocatable...), // `enforce-node-allocatable` 参数设置， KubeReserved: kubeReserved, SystemReserved: systemReserved, ReservedSystemCPUs: reservedSystemCPUs, // 预留给节点其他无关进程的 cpu. HardEvictionThresholds: hardEvictionThresholds, }, QOSReserved: *experimentalQOSReserved, ExperimentalCPUManagerPolicy: s.CPUManagerPolicy, ExperimentalCPUManagerReconcilePeriod: s.CPUManagerReconcilePeriod.Duration, ExperimentalPodPidsLimit: s.PodPidsLimit, EnforceCPULimits: s.CPUCFSQuota, CPUCFSQuotaPeriod: s.CPUCFSQuotaPeriod.Duration, ExperimentalTopologyManagerPolicy: s.TopologyManagerPolicy, }, s.FailSwapOn, devicePluginEnabled, kubeDeps.Recorder) 通过如上 模块设计， Pod 的 allocatable resource 可以通过简单的减法运算得出\nallocatable = NodeCapacity - [kube-reserved] - [system-reserved] - [eviction-threshold]\n我们的测试集群目前配置如下：\nCgroupDriver : systemd SystemCgroups: /system.slice KubeletCgroups: /system.slice SystemReservedCgroups: /system.slice KubeReservedCgroups: /system.slice/kubelet.service 额外的：\nVM 相关 cgroup 配置位于 /system.slice/machine.slice， 需要纳入 node的 统一管理。 QOS level 在上一节 Node 相关配置中， --cgroup-per-qos 配置（默认为 true） 会生成该层级的 Cgroup 配置。\n目前 QOS 共分为 3 种。\nqos 级别\nGuaranteed【老板（我要的都是我的）】：pod 里每个容器都必须设定 request 和 limit，并且值必须相同 Burstable 【洗碗工（底薪+提成）】：pod 里至少有一个容器的 cpu 或者 memory 设置了 request 值 BestEffort【切格瓦拉（能偷到的都是我的）】：POD 的所有容器都没有指定CPU和内存的 request 和 limit 初始化过程发生在 kl.containerLogManager.Start() \u0026gt; setupNode 过程：\n1 2 3 4 5 6 7 8 9 10 // Setup top level qos containers only if CgroupsPerQOS flag is specified as true if cm.NodeConfig.CgroupsPerQOS { if err := cm.createNodeAllocatableCgroups(); err != nil { return err } err = cm.qosContainerManager.Start(cm.getNodeAllocatableAbsolute, activePods) if err != nil { return fmt.Errorf(\u0026#34;failed to initialize top level QOS containers: %v\u0026#34;, err) } } createNodeAllocatableCgroups 会初始化 一个 system.slice/kubepods.slice cgroup, 用于放置 pod 资源\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // Top level for Qos containers are created only for Burstable // and Best Effort classes qosClasses := map[v1.PodQOSClass]CgroupName{ v1.PodQOSBurstable: NewCgroupName(rootContainer, strings.ToLower(string(v1.PodQOSBurstable))), v1.PodQOSBestEffort: NewCgroupName(rootContainer, strings.ToLower(string(v1.PodQOSBestEffort))), } // ... // Store the top level qos container names m.qosContainersInfo = QOSContainersInfo{ Guaranteed: rootContainer, Burstable: qosClasses[v1.PodQOSBurstable], BestEffort: qosClasses[v1.PodQOSBestEffort], } 初始化后 Burstable 和 BestEffort类型的pod cgroup 会被生成在， /system.slice/kubepods.slice 下。\n而 guaranteed 类型 pod 会直接 运行在 /system.slice/kubepods.slice 下.\n这里发生了 kubelet 层的第一次 cgroup 设置： BestEffort其中的 cpu.shares 被设置为minShares(=2).\n表示 在 cpu高负载情况下， BestEffort. Pod 将会享有 pod中最少的的cpu时间段。\n同时，在containerManager start 之后， 还会有一个常驻go程 循环执行 UpdateCgroups():\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 func (m *qosContainerManagerImpl) UpdateCgroups() error { m.Lock() defer m.Unlock() qosConfigs := map[v1.PodQOSClass]*CgroupConfig{ v1.PodQOSBurstable: { Name: m.qosContainersInfo.Burstable, ResourceParameters: \u0026amp;ResourceConfig{}, }, v1.PodQOSBestEffort: { Name: m.qosContainersInfo.BestEffort, ResourceParameters: \u0026amp;ResourceConfig{}, }, } // update the qos level cgroup settings for cpu shares if err := m.setCPUCgroupConfig(qosConfigs); err != nil { return err } // update the qos level cgroup settings for huge pages (ensure they remain unbounded) if err := m.setHugePagesConfig(qosConfigs); err != nil { return err } if utilfeature.DefaultFeatureGate.Enabled(kubefeatures.QOSReserved) { for resource, percentReserve := range m.qosReserved { switch resource { case v1.ResourceMemory: m.setMemoryReserve(qosConfigs, percentReserve) } } updateSuccess := true for _, config := range qosConfigs { err := m.cgroupManager.Update(config) if err != nil { updateSuccess = false } } if updateSuccess { klog.V(4).Infof(\u0026#34;[ContainerManager]: Updated QoS cgroup configuration\u0026#34;) return nil } // If the resource can adjust the ResourceConfig to increase likelihood of // success, call the adjustment function here. Otherwise, the Update() will // be called again with the same values. for resource, percentReserve := range m.qosReserved { switch resource { case v1.ResourceMemory: m.retrySetMemoryReserve(qosConfigs, percentReserve) } } } for _, config := range qosConfigs { err := m.cgroupManager.Update(config) if err != nil { klog.Errorf(\u0026#34;[ContainerManager]: Failed to update QoS cgroup configuration\u0026#34;) return err } } klog.V(4).Infof(\u0026#34;[ContainerManager]: Updated QoS cgroup configuration\u0026#34;) return nil } 该流程保证了 kubepod 相关meta配置不被串改。\nPod level 上两层的 cgroup 配置 大多属于模块划分相关的内容， Pod level 的 cgroup 配置 则更接近于 k8s 需要着重了解的一层。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // Create Cgroups for the pod and apply resource parameters // to them if cgroups-per-qos flag is enabled. // TODO(yuhua): pod cgroup 创建 pcm := kl.containerManager.NewPodContainerManager() // If pod has already been terminated then we need not create // or update the pod\u0026#39;s cgroup if !kl.podIsTerminated(pod) { // When the kubelet is restarted with the cgroups-per-qos // flag enabled, all the pod\u0026#39;s running containers // should be killed intermittently and brought back up // under the qos cgroup hierarchy. // Check if this is the pod\u0026#39;s first sync firstSync := true for _, containerStatus := range apiPodStatus.ContainerStatuses { if containerStatus.State.Running != nil { firstSync = false break } } // Don\u0026#39;t kill containers in pod if pod\u0026#39;s cgroups already // exists or the pod is running for the first time podKilled := false if !pcm.Exists(pod) \u0026amp;\u0026amp; !firstSync { if err := kl.killPod(pod, nil, podStatus, nil); err == nil { podKilled = true } } // Create and Update pod\u0026#39;s Cgroups // Don\u0026#39;t create cgroups for run once pod if it was killed above // The current policy is not to restart the run once pods when // the kubelet is restarted with the new flag as run once pods are // expected to run only once and if the kubelet is restarted then // they are not expected to run again. // We don\u0026#39;t create and apply updates to cgroup if its a run once pod and was killed above if !(podKilled \u0026amp;\u0026amp; pod.Spec.RestartPolicy == v1.RestartPolicyNever) { if !pcm.Exists(pod) { if err := kl.containerManager.UpdateQOSCgroups(); err != nil { klog.V(2).Infof(\u0026#34;Failed to update QoS cgroups while syncing pod: %v\u0026#34;, err) } if err := pcm.EnsureExists(pod); err != nil { kl.recorder.Eventf(pod, v1.EventTypeWarning, events.FailedToCreatePodContainer, \u0026#34;unable to ensure pod container exists: %v\u0026#34;, err) return fmt.Errorf(\u0026#34;failed to ensure that the pod: %v cgroups exist and are correctly applied: %v\u0026#34;, pod.UID, err) } } } } 上述流程我们需要关注的是 如下几个流程\nsyncPod -\u0026gt; kl.containerManager.NewPodContainerManager() -\u0026gt; pcm.Exists(pod) -\u0026gt; kl.containerManager.UpdateQOSCgroups()\nNewPodContainerManager 并没有实质性的cgroup操作，紧跟着的判断 Exists(pod)-\u0026gt; GetPodContainerName函数调用会尝试获取 当前 pod应当存在的 cgroup路径。并检查 pod 对应cgroup的存在。\n如果发现不存在 对应cgroup 则进入创建流程 【创建cgroup 发生在 pod其他资源创建前】， 即 UpdateQOSChroups:\n还函数会进行：\nsetCPUCgroupConfig 比如说保证 BestEffort pod cpu share =2; 计算 Burst.slice 路径 cpu shares 设置应该为 所有 burstable_pod_CPU_request 的和。 setMemoryReserve 取决于是否开启了特性功能 QOSReserved, 该功能会为 Burstable 和 BestEffort pod slice 设置 可用内存上限， 基于实时计算的各个类型的 pod的 内存使用状况。 【暂定默认关闭】 setHugePagesConfig 根据功能开关设置 hugepage 用量。【暂定默认关闭】 上述动作完成后 将会执行 pod 粒度 的 cgroup 创建， 更新操作 EnsureExists\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // EnsureExists takes a pod as argument and makes sure that // pod cgroup exists if qos cgroup hierarchy flag is enabled. // If the pod level container doesn\u0026#39;t already exist it is created. func (m *podContainerManagerImpl) EnsureExists(pod *v1.Pod) error { podContainerName, _ := m.GetPodContainerName(pod) // check if container already exist alreadyExists := m.Exists(pod) if !alreadyExists { // Create the pod container containerConfig := \u0026amp;CgroupConfig{ Name: podContainerName, ResourceParameters: ResourceConfigForPod(pod, m.enforceCPULimits, m.cpuCFSQuotaPeriod), } if utilfeature.DefaultFeatureGate.Enabled(kubefeatures.SupportPodPidsLimit) \u0026amp;\u0026amp; m.podPidsLimit \u0026gt; 0 { containerConfig.ResourceParameters.PidsLimit = \u0026amp;m.podPidsLimit } if err := m.cgroupManager.Create(containerConfig); err != nil { return fmt.Errorf(\u0026#34;failed to create container for %v : %v\u0026#34;, podContainerName, err) } } // Apply appropriate resource limits on the pod container // Top level qos containers limits are not updated // until we figure how to maintain the desired state in the kubelet. // Because maintaining the desired state is difficult without checkpointing. if err := m.applyLimits(pod); err != nil { return fmt.Errorf(\u0026#34;failed to apply resource limits on container for %v : %v\u0026#34;, podContainerName, err) } return nil } 上述代码中 m.cgroupManager.Create(containerConfig 可以完成 pod 级别的 cgroup创建， 至此我们的 pod cgroup container 已经初具雏形。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 [root@node1]# tree /sys/fs/cgroup/cpu -d /sys/fs/cgroup/cpu ├── kubepods │ ├── besteffort │ │ ├── pode098d78945a4d359594f9c27066aa202 │ │ │ ├── 5fca7a73d4b5c7e7a6c35415e2bfeb5533c5fc1d1b4aa80bc4cb641213ee29a3 │ │ │ └── b10831a7a2cf4e96ff6b186396e9e393e5b02aa8c447e988cc6cca5172fc5c89 │ │ └── podfc7fbc35-bb79-4a33-80a0-371d438f221e │ │ ├── 07703a4a76b926c8432c3a8ab50b69b8dfd2891733a09d830fc1a08f8a8e0a1c │ │ └── 3a7550ae2bd7784bc7f74fa0288d361e6d569595a0ba237bb63cdd5468073316 │ └── burstable │ ├── pod420984c2d6d62f72216bba6857bc368b │ │ ├── 5f734d0677fb4dd0f3e3dd3647be6ad19ec728fd3e28860c6023ea6efb7fc331 │ │ └── 93cd418eaddf86be58b200c109674a36cc04fee0eccfae4a7838a1b0e6a4f978 │ ├── pod4ebb633e-f8ba-43ee-94c7-1cf8c9105555 │ │ └── 1bc40d00174d3ea84f4fce14d734a45115e72e4af394bd7d684d9691e7749995 │ ├── podcd4bc68a-faf3-4c08-8d07-57d25a68ee1b │ │ ├── 62ba8b7c6e1afc62d16b65e0d0ae9f82254260815025ecb6c863fa82c9ea5e8e │ │ └── c7aca0c0fdf230a6378e3325f03242ff561ec95e7f62b3b852f2877af0235792 │ ├── podd4f2a7d434e44edd8e4a0960111bda9f │ │ ├── 08d95544fcd3a5631c5a6a550d42bcddf8319cfb1fbe7f2482d969fc19356466 │ │ └── a7a39f33fddce54c64c4a6d0bf4b499fe3d6b3d7c7f5fc0d54445ade5cad24b1 │ ├── pode8486b59c2c8408b07026a560746b02c │ │ ├── b9fb9af9f1c5991786c6457f5b33c90ee8e33a3d68605d409b7a2c30d5565699 │ │ └── f7f6773069032faa45ef3fc62fe337127fe40795ebc3758d03e149376d18d3da │ ├── pode86c3e73-a96e-4ae8-9ff6-fd401cf5c9aa │ │ ├── 4ad31b5ea0ad5743eeb67628c3bf9275d2131f2132a4bbe7081c05f63c6604ea │ │ └── 5f31deed41c58dbc0a0530b964926968d272e846cf9d91452c40797ace7fb90a │ └── podf27baf8c-6c71-4f3a-9445-0c63eb33d586 │ ├── 1ae1d0d1fb0d44652c8ad8ef2d782628ec04a7b0e6e5718ea6788af178505ba2 │ └── 5e898be28b1cb5ccb7f9f52eddee06c114d7d42b951b256da5544128093216be ├── machine.slice │ └── machine-qemu\\\\x2d18\\\\x2dvm123.scope │ ├── emulator │ └── vcpu0 ├── system.slice └── user.slice machine.slice 是 libvirt 针对每个 qemu 进程生成的 cgroup管理空间. 我们意在将其纳入 k8s cgoup 统计范围内。\nContainer level 上述 Node level 发生在 kubelet 的 SyncPod 函数执行过程中， 同样的， container 相关的 cgroup创建 也是在这之后。\n故事仍然要从pod 创建请求开始， 从 入口处的 kubelet syncLoop -\u0026gt; syncLoopIteration -\u0026gt; HandlePodAddtions -\u0026gt; dispatchWork -\u0026gt; UpdatePod -\u0026gt; managePodLoop -\u0026gt; SyncPod -\u0026gt; kl.containerRuntime.SyncPod\n进入 真正创建 container流程，\n1 2 3 4 5 6 7 8 9 10 11 // SyncPod syncs the running pod into the desired pod by executing following steps: // // 1. Compute sandbox and container changes. // 2. Kill pod sandbox if necessary. // 3. Kill any containers that should not be running. // 4. Create sandbox if necessary. // 5. Create ephemeral containers. // 6. Create init containers. // 7. Create normal containers. // TODO(yuhua): 创建container 之处。 func (m *kubeGenericRuntimeManager) SyncPod(pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, backOff *flowcontrol.Backoff) (result kubecontainer.PodSyncResult) containerRuntime.SyncPod 主要内容涉及到 如下几个步骤\n计算 sandbox 和 container 变化 删除无用sandbox 删除无用 容器 创建沙箱 创建 一次性容器 创建 初始化容器 创建 其他容器。 上述前4步都与 cgroup无关，这里最后的三个创建步骤 都使用了 一些公用逻辑。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // Helper containing boilerplate common to starting all types of containers. // typeName is a label used to describe this type of container in log messages, // currently: \u0026#34;container\u0026#34;, \u0026#34;init container\u0026#34; or \u0026#34;ephemeral container\u0026#34; start := func(typeName string, container *v1.Container) error { startContainerResult := kubecontainer.NewSyncResult(kubecontainer.StartContainer, container.Name) result.AddSyncResult(startContainerResult) isInBackOff, msg, err := m.doBackOff(pod, container, podStatus, backOff) if isInBackOff { startContainerResult.Fail(err, msg) klog.V(4).Infof(\u0026#34;Backing Off restarting %v %+v in pod %v\u0026#34;, typeName, container, format.Pod(pod)) return err } klog.V(4).Infof(\u0026#34;Creating %v %+v in pod %v\u0026#34;, typeName, container, format.Pod(pod)) // NOTE (aramase) podIPs are populated for single stack and dual stack clusters. Send only podIPs. if msg, err := m.startContainer(podSandboxID, podSandboxConfig, container, pod, podStatus, pullSecrets, podIP, podIPs); err != nil { startContainerResult.Fail(err, msg) // known errors that are logged in other places are logged at higher levels here to avoid // repetitive log spam switch { case err == images.ErrImagePullBackOff: klog.V(3).Infof(\u0026#34;%v start failed: %v: %s\u0026#34;, typeName, err, msg) default: utilruntime.HandleError(fmt.Errorf(\u0026#34;%v start failed: %v: %s\u0026#34;, typeName, err, msg)) } return err } 这里只需要关注 startContainer 相关逻辑：\n1 2 3 4 5 6 7 // startContainer starts a container and returns a message indicates why it is failed on error. // It starts the container through the following steps: // * pull the image // * create the container // * start the container // * run the post start lifecycle hooks (if applicable) func (m *kubeGenericRuntimeManager) startContainer(podSandboxID string, podSandboxConfig *runtimeapi.PodSandboxConfig, container *v1.Container, pod *v1.Pod, podStatus *kubecontainer.PodStatus, pullSecrets []v1.Secret, podIP string, podIPs []string) (string, error) 这里的 podSandboxConfig 包含以下字段：\n1 Linux *LinuxPodSandboxConfig `protobuf:\u0026#34;bytes,8,opt,name=linux,proto3\u0026#34; json:\u0026#34;linux,omitempty\u0026#34;` 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // LinuxPodSandboxConfig holds platform-specific configurations for Linux // host platforms and Linux-based containers. type LinuxPodSandboxConfig struct { // Parent cgroup of the PodSandbox. // The cgroupfs style syntax will be used, but the container runtime can // convert it to systemd semantics if needed. CgroupParent string `protobuf:\u0026#34;bytes,1,opt,name=cgroup_parent,json=cgroupParent,proto3\u0026#34; json:\u0026#34;cgroup_parent,omitempty\u0026#34;` // LinuxSandboxSecurityContext holds sandbox security attributes. SecurityContext *LinuxSandboxSecurityContext `protobuf:\u0026#34;bytes,2,opt,name=security_context,json=securityContext,proto3\u0026#34; json:\u0026#34;security_context,omitempty\u0026#34;` // Sysctls holds linux sysctls config for the sandbox. Sysctls map[string]string `protobuf:\u0026#34;bytes,3,rep,name=sysctls,proto3\u0026#34; json:\u0026#34;sysctls,omitempty\u0026#34; protobuf_key:\u0026#34;bytes,1,opt,name=key,proto3\u0026#34; protobuf_val:\u0026#34;bytes,2,opt,name=value,proto3\u0026#34;` XXX_NoUnkeyedLiteral struct{} `json:\u0026#34;-\u0026#34;` XXX_sizecache int32 `json:\u0026#34;-\u0026#34;` } 这里可以看到 CgroupParent 限制了 cgroup创建的 父路径。 至此 k8s 层的cgroup创建过程结束。\n创建结束后的 cgroup拓扑参考 Node章节结果。\n其他相关特性 CPUSet 当 VM 与 Pod 进行混合编排， 虚拟化语义中的 vcpu pin 可以使用 cgroup 的 cpu_set 作为 功能映射\nk8s 中 feature Gate CPUManager 负责 管理 容器的 cpu set 设置 该功能 在 k8s 1.8 进入 alpha, 在 1.10 后 beta， 目前 （k8s 1.17） 仍然属于 beta 状态。\nCPU Manager工作流 CPU Manager为满足条件的Container分配指定的CPUs时，会尽量按照CPU Topology来分配，也就是考虑CPU Affinity，按照如下的优先顺序进行CPUs选择：（Logic CPUs就是Hyperthreads）\n如果Container请求的Logic CPUs数量不小于单块CPU Socket中Logci CPUs数量，那么会优先把整块CPU Socket中的Logic CPUs分配给该Container。 如果Container剩余请求的Logic CPUs数量不小于单块物理CPU Core提供的Logic CPUs数量，那么会优先把整块物理CPU Core上的Logic CPUs分配给该Container。 Container剩余请求的Logic CPUs则从按照如下规则排好序的Logic CPUs列表中选择： number of CPUs available on the same socket number of CPUs available on the same core Discovering CPU topology CPU Manager能正常工作的前提，是发现Node上的CPU Topology，Discovery这部分工作是由cAdvisor完成的。\n在cAdvisor的MachineInfo中通过Topology会记录cpu和mem的Topology信息。其中Topology的每个Node对象就是对应一个CPU Socket。\n创建容器 对于满足前面提到的满足static policy的Container创建时，kubelet会为其按照约定的cpu affinity来为其挑选最优的CPU Set。Container的创建时CPU Manager工作流程大致如下：\nKuberuntime调用容器运行时去创建该Container。\nKuberuntime将该Container交给CPU Manager处理。\nCPU Manager为Container按照static policy逻辑进行处理。\nCPU Manager从当前Shared Pool中挑选“最佳”Set拓扑结构的CPU，对于不满足Static Policy的Contianer，则返回Shared Pool中所有CPUS组成的Set。\nCPU Manager将对该Container的CPUs分配情况记录到Checkpoint State中，并且从Shared Pool中删除刚分配的CPUs。\nCPU Manager再从state中读取该Container的CPU分配信息，然后通过UpdateContainerResources cRI接口将其更新到Cpuset Cgroups中，包括对于非Static Policy Container。\nKuberuntime调用容器运行时Start该容器。\n该过程入口处于 上一章节的 Container level 中的 startContainer 函数：\n1 2 3 4 5 6 7 8 // TODO(yuhua): 设置 CPUset err = m.internalLifecycle.PreStartContainer(pod, container, containerID) if err != nil { s, _ := grpcstatus.FromError(err) m.recordContainerEvent(pod, container, containerID, v1.EventTypeWarning, events.FailedToStartContainer, \u0026#34;Internal PreStartContainer hook failed: %v\u0026#34;, s.Message()) return s.Message(), ErrPreStartHook } 写在最后 libvirt 已经实现了完整的 cgroup 抽象， 但是缺少完整的 cgroup 管理流程，如果想要通过 cgroup将 vm 资源抽象 并与 Pod 的资源做统一管理， 我们在前端 （kubelet） 及 对应的 后端 （VRI） 设计完整的 cgroup 操作流程。\n参考: k8s cpu manager libvirt cgroups ","date":"2020-01-14T11:35:58+08:00","permalink":"http://blog.heyuhua.com/p/%E4%BB%8Ekubelet-cgroup-%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B%E5%85%A5%E6%89%8B/","title":"从kubelet Cgroup 管理流程入手"},{"content":"这里缅怀 gonum社区的一位杰出贡献者. Sonia Keys.\nSonia 是一位 业余天文学家，在03年被授予太平洋天文学杰出贡献奖。Golang 狂热爱好者， golang社区 数学及图形相关项目作者。\nOCI 协议中定义了 update api，但是上层的 k8s 编排层却一直缺少了相关的 container 热更新机制。在新产品的 技术调研中， kyle发现了上述功能提案，这里详细概括之。\nVertical pod auto scaler， GKE 文档 有详细的中文介绍， 社区一般将该功能简称为 VPA. 设计目的是为了能够调整 pod CPU / Memory 的request limit限制。\n这里我们希望在 VPA 实现中寻找一个方式能够有所帮助，或者能给予启发。\n摘抄自 GKE：\n概览 垂直 Pod 自动扩缩 (VPA) 使您不必考虑为容器的 CPU 请求和内存求指定具体的值。自动调节程序可以为 CPU 和内存请求和限制建议值，也可以自动更新值。\n垂直 Pod 自动扩缩提供以下好处：\n因为 Pod 完全用其所需，所以集群节点使用效率高。 Pod 会被安排到具有适当可用资源的节点上。 您不必运行耗时的基准测试任务来确定 CPU 和内存请求的正确值。 自动调节程序可以随时调整 CPU 和内存请求，而无需您执行任何操作，所以维护时间更短。 ok ，别人家的瓜只能吃到这里了。\n漫长的 G站扫街环节后。。。\n该功能的设计环节较为挫折，第一次参与人数较多的 讨论发生在 16年年初，隶属于 sig-node 小组，之后被重新分配到了 sig-autoscaling 小组下。 大概经过了 3年左右的开发周期。 将在近期（k8s 1.18 ）GA.\n设计方案详细描写了技术细节。这里会挑一些重点介绍。\n介绍 技术细节 资源计算 资源Qos 准入控制 外部准入控制 目标： 引入自动维护，减少维护成本。 提高资源利用率，减少container OOM 发生的情况。 相关功能 HPA( Horizontal Pod Autoscaler) 横向扩展， 通过监听 cpu 压力和其他用户指定的 metric 动态缩扩。一般情况下 用户将会对无状态负载制定 HPA 方案，对有状态服务设置 VPA.\nCA (Cluster Autoscaler) 自动进行集群大小的配置。 可以和 VPA, HPA 组成完整的自动化伸缩方案。\ninitial resources 概念性的功能，基于历史利用率指标， 可以在pod创建时给予resource建议。 VPA 会覆盖重写该功能。\nResource estimation 资源预算, 旨在提高节点资源的利用率。通过临时回收容器当前未使用的资源。 可以对标虚拟化的 DMC.概念和实现。使用Node pod 短时间时序数据进行资源回收和释放。 该功能与 VPA 互补。 仍处于设计阶段。\n需求 功能特性 VPA 可以修改 POD 的资源 request/limit VPA 可以对 CPU 高负载， 内存 OOM 的事件作出相应。 重启 VPA 管理下的 pod 可以遵循破坏预算功能（disruption budget） VPA 可配置：用户可以制定 VPA 动态缩扩的上下限。 VPA 支持 pod controller,至少支持 deployment. \u0026hellip;..\n其他:\n- 高可用的 - 在 in-place update 功能完成后可以自动支持。（我们关注的重点之一） 设计 添加了一个 新的 API Server资源vertialPodAutoscaler, 包含了一个label selector去筛选 pod，使用 resources policy控制如何将pod 的配置更新， 并且给出推荐的 pod resource 配置。 一个新的组件 VPA Recommender ，从 metrics-server 响应消费集群所有的 pod 资源负载信号， 和 OOM 信号. VPA Recommender 监听所有的 pods，持续计算针对这些pod 的推荐资源用量，并存储在 VPA 对象中。 VPA Recommender 还会额外的 暴露一个同步 API ，可以获取 POD 描述， 并且返回 推荐的 资源配置。 所有的Pod 资源创建请求 会经由 VPA 的 Admission Controller，如果pod 可以匹配到任何读经的 VPA 对象，该访问控制插件会将 pod 的 资源字段，如果 上面的 VPA recommender 不可访问， 则会降级到使用已经缓存的vpa资源。 另一个独立组件 VPA Updater，负责实施更新 pods，如果一个 pod 使用 “auto”模式的 VPA 配置，则该组件可以自动决定更新其 resource 配置到推荐值。这里要求 pod资源需要隶属于其他上层抽象管理资源，如 replicaset等,可以在 pod因为修改配置后被销毁后重新创建。 在之后的更新中， Updater 会引入 in-place-update 模式, 可以绕过 上述管理资源，因其可以直接在pod不销毁的情况下进行资源修改。 CPA 之 控制资源的 下限，即 resource 的 request，但会将其limit设置为 infinity. 其 request 的数值根据 当前和之前运行时的 监控数据计算得出。 新组件：History Storage，同样的， 会消费来自 API Server 的资源利用率和OOM 事件（与 Recommender 组件相同），并且将其持久化存储。 该组件被 Recommender 用作在 启动时初始化。 可以由任意数据库支持。 MVP版本使用 Prometheus, 至少对于 资源使用率的部分是这样的。 架构图 API 上面的 API 对象 verticalPodAutoscaler 的一些详细信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // VerticalPodAutoscalerSpec is the specification of the behavior of the autoscaler. type VerticalPodAutoscalerSpec { // A label query that determines the set of pods controlled by the Autoscaler. // More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors Selector *metav1.LabelSelector // Describes the rules on how changes are applied to the pods. // +optional UpdatePolicy PodUpdatePolicy // Controls how the autoscaler computes recommended resources. // +optional ResourcePolicy PodResourcePolicy } // VerticalPodAutoscalerStatus describes the runtime state of the autoscaler. type VerticalPodAutoscalerStatus { // The time when the status was last refreshed. LastUpdateTime metav1.Time // The most recently computed amount of resources recommended by the // autoscaler for the controlled pods. // +optional Recommendation RecommendedPodResources\t// A free-form human readable message describing the status of the autoscaler. StatusMessage string } Selector 指明了 哪些pod会被 VPA 控制。 也就是说 用户需要在编辑 pod时确保 label中包含了 VPA的信息。\nUpdate Policy 1 2 3 \u0026#34;updatePolicy\u0026#34; { \u0026#34;mode\u0026#34;: \u0026#34;\u0026#34;, }\t模式指定。 VPA 包含三种resource 自动伸缩策略。\n\u0026ldquo;Initial\u0026rdquo;: VPA 只在 创建 pod时指定资源，在之后的pod生命周期中都不做修改。 \u0026ldquo;Auto\u0026quot;(defualt): 可以在 Pod 创建和运行时更新，包括驱逐， 重新规划（reschedule). \u0026ldquo;off\u0026rdquo;：没什么卵用的开发用功能。不作为，但是会记录运行时metric. Resource Policy 资源上下限。自动伸缩波动范围 threshold.\n写到这里应该是差不多了。 后面的实现细节并不设计 resource in-place update 相关内容。\n","date":"2020-01-09T11:30:34+08:00","permalink":"http://blog.heyuhua.com/p/vertical-scaling-of-pods-pod%E7%83%AD%E7%BC%A9%E6%94%BE/","title":"Vertical Scaling of Pods | pod热缩放"},{"content":" In code we trust. \u0026ndash;BitCoin\nnumpy.rollaxis 的另类理解方式 rollaxis 实例 in[1]:\n1 2 3 4 %matplotlib inline import matplotlib.pyplot as plt import numpy as np import scipy.misc in[2]:\n1 b = scipy.misc.imread(\u0026#39;magic.png\u0026#39;) in[3]:\n1 b.dtype out[3]:\n1 dtype(\u0026#39;uint8\u0026#39;) in[4]:\n1 toimage(b) out[4]:\nin[5]:\n1 b.shape out[5]:\n1 (810, 572, 4) in[6]: 该操作与 c = np.swapaxes(b, 0, 1) 等效\n1 c = np.rollasix(b, 1) in[7]:\n1 c.shape out[7]:\n1 (572, 810, 4) in[8]:\n1 toimage(c) out[9]:\npython常用设计模式 行文结构参照以下项目。 项目地址： https://github.com/faif/python-patterns\n《松本行弘的程序世界》对三人组的《设计模式》称赞有加：\n把普通人难以学习和吸收的内隐知识变成形式只是的功绩是无与伦比的。\n在设计模式原书中一共提到23种常用的设计模式，分为三大类：生成模式（creational）， 构造模式（structural）， 行为模式（behavioral）。该项目同样按照这三大类进行了分类整理， 同时还补充了一些python常用的其他场景的特用模式。 在整理这片文章的过程中，我忽略了一些无聊的模式，并引用或者另写了一些更好的代码用例。\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;生成模式\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nabstract_factory / 抽象工厂 最直白的就是“鸡鸭鹅狗猫都是动物”：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from abc import ABCMeta, abstractmethod # Pet类是一个典型的抽象类, 包含了抽象方法 `speak` # 其类方法from_name 充当了 工厂“销售“ 的角色，对于所有的Pet子类，客户想要什么就可以得到什么。 class Pet(metaclass=ABCMeta): @classmethod def from_name(cls, name): for sub_cls in cls.__subclasses__(): if name == sub_cls.__name__.lower(): return sub_cls() @abstractmethod def speak(self): \u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34;\u0026#34; class Kitty(Pet): def speak(self): return \u0026#34;Miao\u0026#34; class Duck(Pet): def speak(self): return \u0026#34;Quak\u0026#34; for name in [\u0026#39;kitty\u0026#39;, \u0026#39;duck\u0026#39;]: pet = Pet.from_name(name) print(\u0026#34;{}: {}\u0026#34;.format(name, pet.speak())) # kitty: Miao # duck: Quak borg / 集体主义模式 emmm\u0026hellip; https://blog.youxu.info/2010/04/29/borg/ 介绍了borg的出处。 borg就是python的singleton，但是与singleton不同的是，borg模式为多个对象共享单一状态， 而不是单一对象多个引用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Borg(object): __shared_state = {} def __init__(self): self.__dict__ = self.__shared_state self.state = \u0026#39;Init\u0026#39; def __str__(self): return self.state # ipython excemple # In [2]: a = Borg() # In [3]: b = Borg() # In [4]: a.state # Out[4]: \u0026#39;Init\u0026#39; # In [5]: b.state # Out[5]: \u0026#39;Init\u0026#39; # In [6]: a.state=\u0026#39;123\u0026#39; # In [7]: b.state # Out[7]: \u0026#39;123\u0026#39; # In [8]: id(a) # Out[8]: 4340743360 # In [9]: id(b) # Out[9]: 4340673448 builder / 建造者模式 适用于构造复杂对象, 将构造过程拆分为独立模块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # copy from《Mastering Python Design Patterns》 class Computer: def __init__(self, serial_number): self.serial = serial_number self.memory = None self.cpu = None self.disk = None def __str__(self): return \u0026#39;memory: {0} GB, cpu: {1}, disk: {2} GB\u0026#39;.format( self.memory, self.cpu, self.disk ) class ComputerBuilder: def __init__(self): self.computer = Computer(\u0026#39;SN-12345555\u0026#39;) def configure_memory(self, memory): self.computer.memory = memory def configure_cpu(self, cpu): self.computer.cpu = cpu def configure_disk(self, disk): self.computer.disk = disk class HardwareEngineer: def __init__(self): self.builder = None def construct_computer(self, memory, cpu, disk): self.builder = ComputerBuilder() self.builder.configure_memory(memory) self.builder.configure_cpu(cpu) self.builder.configure_disk(disk) @property def computer(self): return self.builder.computer engineer = HardwareEngineer() engineer.construct_computer(16, 8, 500) computer = engineer.computer print(computer) # memory: 16 GB, cpu: 8, disk: 500 GB factory / 工厂模式 抽象工厂和工厂模式在python实现中的区别大概只是有没有继承关系了。。。 同样的，工厂方法也是用来实现通用接口。比如说下面这种多国语言翻译的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class GreekGetter(object): \u0026#34;\u0026#34;\u0026#34;A simple localizer a la gettext\u0026#34;\u0026#34;\u0026#34; def __init__(self): self.trans = dict(dog=\u0026#34;σκύλος\u0026#34;, cat=\u0026#34;γάτα\u0026#34;) def get(self, msgid): \u0026#34;\u0026#34;\u0026#34;We\u0026#39;ll punt if we don\u0026#39;t have a translation\u0026#34;\u0026#34;\u0026#34; return self.trans.get(msgid, str(msgid)) class EnglishGetter(object): \u0026#34;\u0026#34;\u0026#34;Simply echoes the msg ids\u0026#34;\u0026#34;\u0026#34; def get(self, msgid): return str(msgid) def get_localizer(language=\u0026#34;English\u0026#34;): \u0026#34;\u0026#34;\u0026#34;The factory method\u0026#34;\u0026#34;\u0026#34; languages = dict(English=EnglishGetter, Greek=GreekGetter) return languages[language]() if __name__ == \u0026#39;__main__\u0026#39;: # Create our localizers e, g = get_localizer(language=\u0026#34;English\u0026#34;), get_localizer(language=\u0026#34;Greek\u0026#34;) # Localize some text for msgid in \u0026#34;dog parrot cat bear\u0026#34;.split(): print(e.get(msgid), g.get(msgid)) ### OUTPUT ### # dog σκύλος # parrot parrot # cat γάτα # bear bear lazy_evaluation\t/ 惰性求值 Delays the eval of an expr until its value is needed and avoids repeated evals.\n表达式计算延迟到调用时，同时避免重复计算\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 import functools class cached_property(object): def __init__(self, function): self.function = function functools.update_wrapper(self, function) def __get__(self, obj, type_): if obj is None: return self val = self.function(obj) obj.__dict__[self.function.__name__] = val return val The cached_property(a.k.a lazy_property) is a decorator which convert a func into a lazy evaluation property. The first time property accessed, the func is called to get result and then the value is used the next time you access the property.\neg:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class LogHandler: def __init__(self, file_path): self.file_path = file_path @cached_property def load_log_file(self): with open(self.file_path) as f: # the file is to big that I have to cost 2s to read all file return f.read() log_handler = LogHandler(\u0026#39;./sys.log\u0026#39;) # only the first time call will cost 2s. print(log_handler.load_log_file) # return value is cached to the log_handler obj. print(log_handler.load_log_file) pool /池模式 预初始化一批对象并保持可用状态。 pool模式常用来提供各种服务连接，比如各大数据库提供的ConnectionPool, python内建的 threadingPools。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 import queue class ObjPool: def __init__(self, queue, auto_get=False): self._queue = queue self.item = self._queue.get() if auto_get else None def __enter__(self): if self.item is None: self.item = self._queue.get() return self.item def __exit__(self, exc_type, exc_val, exc_tb): if self.item is not None: self._queue.put(self.item) self. item = None def __del__(self): if self.item is not None: self._queue.put(self.item) self. item = None my_queue = queue.Queue(maxsize=20) my_queue.put(\u0026#39;huahua\u0026#39;) my_queue.put(\u0026#39;dandan\u0026#39;) def do_sth_in_queue(myqueue): with ObjPool(myqueue) as obj: print(f\u0026#39;inside {obj}\u0026#39;) out_item = myqueue.get() print(f\u0026#39;outside {out_item}\u0026#39;) myqueue.put(out_item) while True: with ObjPool(myqueue) as obj: print(f\u0026#39;inside {obj}\u0026#39;) do_sth_in_queue(my_queue) # inside huahua # inside dandan # inside huahua # inside dandan # inside huahua # inside dandan # ... protopype / 原型 通过clone原型来创建新的实例。似乎并没有人用过。。。\n1 2 3 4 5 6 7 8 9 10 class Prototype(object): value = \u0026#39;default\u0026#39; def clone(self, **attrs): \u0026#34;\u0026#34;\u0026#34;Clone a prototype and update inner attributes dictionary\u0026#34;\u0026#34;\u0026#34; # Python in Practice, Mark Summerfield obj = self.__class__() obj.__dict__.update(attrs) return obj \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;生成模式\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nadapter / 适配器 我想起了10年前家里用的万能充：万能充总是能通过改变自己的接口形状来适应不同的手机电池。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 class Dog(object): def __init__(self): self.name = \u0026#34;Dog\u0026#34; def bark(self): return \u0026#34;woof!\u0026#34; class Cat(object): def __init__(self): self.name = \u0026#34;Cat\u0026#34; def meow(self): return \u0026#34;meow!\u0026#34; class Human(object): def __init__(self): self.name = \u0026#34;Human\u0026#34; def speak(self): return \u0026#34;\u0026#39;hello\u0026#39;\u0026#34; class Car(object): def __init__(self): self.name = \u0026#34;Car\u0026#34; def make_noise(self, octane_level): return \u0026#34;vroom{0}\u0026#34;.format(\u0026#34;!\u0026#34; * octane_level) class Adapter(object): \u0026#34;\u0026#34;\u0026#34; Adapts an object by replacing methods. Usage: dog = Dog dog = Adapter(dog, dict(make_noise=dog.bark)) \u0026gt;\u0026gt;\u0026gt; objects = [] \u0026gt;\u0026gt;\u0026gt; dog = Dog() \u0026gt;\u0026gt;\u0026gt; print(dog.__dict__) {\u0026#39;name\u0026#39;: \u0026#39;Dog\u0026#39;} \u0026gt;\u0026gt;\u0026gt; objects.append(Adapter(dog, make_noise=dog.bark)) \u0026gt;\u0026gt;\u0026gt; print(objects[0].original_dict()) {\u0026#39;name\u0026#39;: \u0026#39;Dog\u0026#39;} \u0026gt;\u0026gt;\u0026gt; cat = Cat() \u0026gt;\u0026gt;\u0026gt; objects.append(Adapter(cat, make_noise=cat.meow)) \u0026gt;\u0026gt;\u0026gt; human = Human() \u0026gt;\u0026gt;\u0026gt; objects.append(Adapter(human, make_noise=human.speak)) \u0026gt;\u0026gt;\u0026gt; car = Car() \u0026gt;\u0026gt;\u0026gt; car_noise = lambda: car.make_noise(3) \u0026gt;\u0026gt;\u0026gt; objects.append(Adapter(car, make_noise=car_noise)) \u0026gt;\u0026gt;\u0026gt; for obj in objects: ... print(\u0026#39;A {} goes {}\u0026#39;.format(obj.name, obj.make_noise())) A Dog goes woof! A Cat goes meow! A Human goes \u0026#39;hello\u0026#39; A Car goes vroom!!! \u0026#34;\u0026#34;\u0026#34; def __init__(self, obj, **adapted_methods): \u0026#34;\u0026#34;\u0026#34;We set the adapted methods in the object\u0026#39;s dict\u0026#34;\u0026#34;\u0026#34; self.obj = obj self.__dict__.update(adapted_methods) def __getattr__(self, attr): \u0026#34;\u0026#34;\u0026#34;All non-adapted calls are passed to the object\u0026#34;\u0026#34;\u0026#34; return getattr(self.obj, attr) def original_dict(self): \u0026#34;\u0026#34;\u0026#34;Print original object dict\u0026#34;\u0026#34;\u0026#34; return self.obj.__dict__ bridge / 桥接模式 桥接的使用集中在频繁更换实现方法时。用于把容易拆分的实现抽象成接口。然后挑选使用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 # ConcreteImplementor 1/2 class DrawingAPI1(object): def draw_circle(self, x, y, radius): print(\u0026#39;API1.circle at {}:{} radius {}\u0026#39;.format(x, y, radius)) # ConcreteImplementor 2/2 class DrawingAPI2(object): def draw_circle(self, x, y, radius): print(\u0026#39;API2.circle at {}:{} radius {}\u0026#39;.format(x, y, radius)) # Refined Abstraction class CircleShape(object): def __init__(self, x, y, radius, drawing_api): self._x = x self._y = y self._radius = radius self._drawing_api = drawing_api # low-level i.e. Implementation specific def draw(self): self._drawing_api.draw_circle(self._x, self._y, self._radius) # high-level i.e. Abstraction specific def scale(self, pct): self._radius *= pct def main(): shapes = ( CircleShape(1, 2, 3, DrawingAPI1()), CircleShape(5, 7, 11, DrawingAPI2()) ) for shape in shapes: shape.scale(2.5) shape.draw() if __name__ == \u0026#39;__main__\u0026#39;: main() ### OUTPUT ### # API1.circle at 1:2 radius 7.5 # API2.circle at 5:7 radius 27.5 composite / 组合模式 一种表达树形结构的方法,恕在下才疏学浅，还没有注意到生产代码中的类似用例。 贴一段 soucemaking上的用例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 import abc class Component(metaclass=abc.ABCMeta): \u0026#34;\u0026#34;\u0026#34; Declare the interface for objects in the composition. Implement default behavior for the interface common to all classes, as appropriate. Declare an interface for accessing and managing its child components. Define an interface for accessing a component\u0026#39;s parent in the recursive structure, and implement it if that\u0026#39;s appropriate (optional). \u0026#34;\u0026#34;\u0026#34; @abc.abstractmethod def operation(self): pass class Composite(Component): \u0026#34;\u0026#34;\u0026#34; Define behavior for components having children. Store child components. Implement child-related operations in the Component interface. \u0026#34;\u0026#34;\u0026#34; def __init__(self): self._children = set() def operation(self): for child in self._children: child.operation() def add(self, component): self._children.add(component) def remove(self, component): self._children.discard(component) class Leaf(Component): \u0026#34;\u0026#34;\u0026#34; Represent leaf objects in the composition. A leaf has no children. Define behavior for primitive objects in the composition. \u0026#34;\u0026#34;\u0026#34; def operation(self): pass def main(): leaf = Leaf() composite = Composite() composite.add(leaf) composite.operation() if __name__ == \u0026#34;__main__\u0026#34;: main() faced / 门面 可以叫它总闸模式： 一个独立的模块单独负责所有子对象的运行。 举个极其抽象的例子：\n1 2 3 4 5 6 7 def runner(): a = lambda: \u0026#34;task a\u0026#34; b = lambda: \u0026#34;task b\u0026#34; c = lambda: \u0026#34;task c\u0026#34; tasks = [a, b, c] task_ret = [task() for task in tasks] print(task_ret) flyweight / 享元 通过与其他相似的对象共享数据来达到节省内存的目的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; *References: http://codesnipers.com/?q=python-flyweights http://yloiseau.net/articles/DesignPatterns/flyweight/ *TL;DR80 Minimizes memory usage by sharing data with other similar objects. \u0026#34;\u0026#34;\u0026#34; import weakref class FlyweightMeta(type): def __new__(mcs, name, parents, dct): \u0026#34;\u0026#34;\u0026#34; Set up object pool :param name: class name :param parents: class parents :param dct: dict: includes class attributes, class methods, static methods, etc :return: new class \u0026#34;\u0026#34;\u0026#34; dct[\u0026#39;pool\u0026#39;] = weakref.WeakValueDictionary() # 调用 type 的 new 方法。 return super(FlyweightMeta, mcs).__new__(mcs, name, parents, dct) @staticmethod def _serialize_params(cls, *args, **kwargs): \u0026#34;\u0026#34;\u0026#34; Serialize input parameters to a key. Simple implementation is just to serialize it as a string \u0026#34;\u0026#34;\u0026#34; args_list = list(map(str, args)) args_list.extend([str(kwargs), cls.__name__]) key = \u0026#39;\u0026#39;.join(args_list) return key def __call__(cls, *args, **kwargs): key = FlyweightMeta._serialize_params(cls, *args, **kwargs) pool = getattr(cls, \u0026#39;pool\u0026#39;, {}) instance = pool.get(key) if instance is None: instance = super(FlyweightMeta, cls).__call__(*args, **kwargs) pool[key] = instance return instance def with_metaclass(meta, *bases): \u0026#34;\u0026#34;\u0026#34; Provide python cross-version metaclass compatibility. \u0026#34;\u0026#34;\u0026#34; return meta(\u0026#34;NewBase\u0026#34;, bases, {}) class Card2(with_metaclass(FlyweightMeta)): def __init__(self, *args, **kwargs): pass if __name__ == \u0026#39;__main__\u0026#39;: # comment __new__ and uncomment __init__ to see the difference # Tests with metaclass instances_pool = getattr(Card2, \u0026#39;pool\u0026#39;) cm1 = Card2(\u0026#39;10\u0026#39;, \u0026#39;h\u0026#39;, a=1) cm2 = Card2(\u0026#39;10\u0026#39;, \u0026#39;h\u0026#39;, a=1) cm3 = Card2(\u0026#39;10\u0026#39;, \u0026#39;h\u0026#39;, a=2) print(f\u0026#39;id:{id(cm1)}, {cm1}\u0026#39;) print(f\u0026#39;id:{id(cm2)}, {cm2}\u0026#39;) print(f\u0026#39;id:{id(cm3)}, {cm3}\u0026#39;) assert (cm1 == cm2) != cm3 assert (cm1 is cm2) is not cm3 assert len(instances_pool) == 2 del cm1 assert len(instances_pool) == 2 del cm2 assert len(instances_pool) == 1 del cm3 assert len(instances_pool) == 0 front controtllor / 前端控制器 front controtollr 提供了一个中控平台控制和管理请求。\n1 # 点击右上角查看示例 mvc\u0026amp;n-tier / 分层 mvc 和 n-tier 的差别就是， n-tier 模式中各模块为线性关系，而 mvc结构中，view 向controllor 发送更新信息，controllor更新model，然后view层获取model层的更新。\n在应用中，我们通常用mvc，mvvc等来形容app的代码层级结构，而在基础设施搭建中，我们通常用n-tier来 描述该协议/模式的运行模式。比如网络的7层/3层结构。\nmvc\n1 # 点击右上角查看示例 3-tier\n1 # 点击右上角查看示例 proxy / 代理 代理的核心思想是控制对一个对象的访问过程，比如网络代理，控制了网络访问的过程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 # 点击右上角查看源网址 \u0026#34;\u0026#34;\u0026#34; Provide a surrogate or placeholder for another object to control access to it or add other responsibilities. \u0026#34;\u0026#34;\u0026#34; import abc class Subject(metaclass=abc.ABCMeta): \u0026#34;\u0026#34;\u0026#34; Define the common interface for RealSubject and Proxy so that a Proxy can be used anywhere a RealSubject is expected. \u0026#34;\u0026#34;\u0026#34; @abc.abstractmethod def request(self): pass class Proxy(Subject): \u0026#34;\u0026#34;\u0026#34; Maintain a reference that lets the proxy access the real subject. Provide an interface identical to Subject\u0026#39;s. \u0026#34;\u0026#34;\u0026#34; def __init__(self, real_subject): self._real_subject = real_subject def request(self): # ... self._real_subject.request() # ... class RealSubject(Subject): \u0026#34;\u0026#34;\u0026#34; Define the real object that the proxy represents. \u0026#34;\u0026#34;\u0026#34; def request(self): pass def main(): real_subject = RealSubject() proxy = Proxy(real_subject) proxy.request() if __name__ == \u0026#34;__main__\u0026#34;: main() \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;行为模式\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nchain / 责任链 责任链将多个对象连成一条链，并且沿着这条链传递请求，直到有对象处理为止。 该模式解耦了请求和处理者 ，客户端只要发送请求到责任链，无需关心请求的处理细节。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 # -*- coding: utf-8 -*- \u0026#34;\u0026#34;\u0026#34; http://www.dabeaz.com/coroutines/ \u0026#34;\u0026#34;\u0026#34; from contextlib import contextmanager import os import sys import time import abc def coroutine(func): def start(*args, **kwargs): cr = func(*args, **kwargs) next(cr) return cr return start @coroutine def coroutine1(target): while True: request = yield if 0 \u0026lt; request \u0026lt;= 10: print(\u0026#39;request {} handled in coroutine 1\u0026#39;.format(request)) else: target.send(request) @coroutine def coroutine2(target): while True: request = yield if 10 \u0026lt; request \u0026lt;= 20: print(\u0026#39;request {} handled in coroutine 2\u0026#39;.format(request)) else: target.send(request) @coroutine def coroutine3(target): while True: request = yield if 20 \u0026lt; request \u0026lt;= 30: print(\u0026#39;request {} handled in coroutine 3\u0026#39;.format(request)) else: target.send(request) @coroutine def default_coroutine(): while True: request = yield print(\u0026#39;end of chain, no coroutine for {}\u0026#39;.format(request)) class ClientCoroutine: def __init__(self): # chain self.target = coroutine1(coroutine3(coroutine2(default_coroutine()))) def delegate(self, requests): for request in requests: self.target.send(request) def timeit(func): def count(*args, **kwargs): start = time.time() res = func(*args, **kwargs) count._time = time.time() - start return res return count @contextmanager def suppress_stdout(): try: stdout, sys.stdout = sys.stdout, open(os.devnull, \u0026#39;w\u0026#39;) yield finally: sys.stdout = stdout if __name__ == \u0026#34;__main__\u0026#34;: client = ClientCoroutine() requests = [2, 5, 14, 22, 18, 3, 35, 27, 20] print(\u0026#39;-\u0026#39; * 30) client.delegate(requests) requests *= 10000 client_delegate = timeit(client.delegate) with suppress_stdout(): client_delegate(requests) command / 命令模式 一种数据驱动的设计模式。请求以命令的形式包裹在对象中，并传给调用对象。调用对象寻找可以 处理该命令的合适的对象，并把该命令传给相应的对象，该对象执行命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 # -*- coding: utf8 -*- import abc from sys import stdout as console # Handling \u0026#39;exit\u0026#39; command class SessionClosed(Exception): def __init__(self, value): self.value = value # Interface class Command(metaclass=abc.ABCMeta): def execute(self): raise NotImplementedError() def cancel(self): raise NotImplementedError() @abc.abstractmethod def name(self): ... # rm command class RmCommand(Command): def execute(self): console.write(\u0026#34;You are executed \\\u0026#34;rm\\\u0026#34; command\\n\u0026#34;) def cancel(self): console.write(\u0026#34;You are canceled \\\u0026#34;rm\\\u0026#34; command\\n\u0026#34;) def name(self): return \u0026#34;rm\u0026#34; # uptime command class UptimeCommand(Command): def execute(self): console.write(\u0026#34;You are executed \\\u0026#34;uptime\\\u0026#34; command\\n\u0026#34;) def cancel(self): console.write(\u0026#34;You are canceled \\\u0026#34;uptime\\\u0026#34; command\\n\u0026#34;) def name(self): return \u0026#34;uptime\u0026#34; # undo command class UndoCommand(Command): def execute(self): try: cmd = HISTORY.pop() TRASH.append(cmd) console.write(\u0026#34;Undo command \\\u0026#34;{0}\\\u0026#34;\\n\u0026#34;.format(cmd.name())) cmd.cancel() except IndexError: console.write(\u0026#34;ERROR: HISTORY is empty\\n\u0026#34;) def name(self): return \u0026#34;undo\u0026#34; # redo command class RedoCommand(Command): def execute(self): try: cmd = TRASH.pop() HISTORY.append(cmd) console.write(\u0026#34;Redo command \\\u0026#34;{0}\\\u0026#34;\\n\u0026#34;.format(cmd.name())) cmd.execute() except IndexError: console.write(\u0026#34;ERROR: TRASH is empty\\n\u0026#34;) def name(self): return \u0026#34;redo\u0026#34; # history command class HistoryCommand(Command): def execute(self): i = 0 for cmd in HISTORY: console.write(\u0026#34;{0}: {1}\\n\u0026#34;.format(i, cmd.name())) i = i + 1 def name(self): print(\u0026#34;history\u0026#34;) # exit command class ExitCommand(Command): def execute(self): raise SessionClosed(\u0026#34;Good day!\u0026#34;) def name(self): return \u0026#34;exit\u0026#34; # available commands COMMANDS = {\u0026#39;rm\u0026#39;: RmCommand(), \u0026#39;uptime\u0026#39;: UptimeCommand(), \u0026#39;undo\u0026#39;: UndoCommand(), \u0026#39;redo\u0026#39;: RedoCommand(), \u0026#39;history\u0026#39;: HistoryCommand(), \u0026#39;exit\u0026#39;: ExitCommand()} HISTORY = list() TRASH = list() # Shell def main(): try: while True: console.flush() console.write(\u0026#34;pysh \u0026gt;\u0026gt; \u0026#34;) cmd = input() try: command = COMMANDS[cmd] command.execute() if (not isinstance(command, UndoCommand) and not isinstance(command, RedoCommand) and not isinstance(command, HistoryCommand)): global TRASH TRASH = list() HISTORY.append(command) except KeyError: console.write(\u0026#34;ERROR: Command \\\u0026#34;%s\\\u0026#34; not found\\n\u0026#34; % cmd) except SessionClosed as e: console.write(e.value) if __name__ == \u0026#34;__main__\u0026#34;: main() iterator / 迭代器 emmm\u0026hellip; class里的 magic methods __next__, __iter__, 函数中的yield, 都可以用来 生成iterator。 一个简单的迭代器。\n1 2 3 4 def aiter(): a = [1 ,2, 3, 4, 4, 5, 5, 6, 6, 7] for i in a: yield i mediator / 中介 用来降低多个对象和类之间的通信复杂性。这种模式提供了一个中介类，该类通常处理不同类之间的通信， 并支持松耦合，使代码易于维护。 \u0026ndash;\u0026gt; 想聊天的人多了，才出现了qq群。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 # # Python Design Patterns: Mediator # Author: Jakub Vojvoda [github.com/JakubVojvoda] # 2016 # # Source code is licensed under MIT License # (for more details see LICENSE) # import sys # # Colleague classes # each colleague communicates with its mediator whenever # it would have otherwise communicated with another colleague # class Colleague: def __init__(self, mediator, identity): self._mediator = mediator self._id = identity def getID(self): return self._id def send(self, message): pass def receive(self, message): pass class ConcreteColleague(Colleague): def __init__(self, mediator, identity): super().__init__(mediator, identity) def send(self, message): print(\u0026#34;Message \u0026#39;\u0026#34; + message + \u0026#34;\u0026#39; sent by Colleague \u0026#34; + str(self._id)) self._mediator.distribute(self, message) def receive(self, message): print(\u0026#34;Message \u0026#39;\u0026#34; + message + \u0026#34;\u0026#39; received by Colleague \u0026#34; + str(self._id)) # # Mediator # defines an interface for communicating with Colleague objects # class Mediator: def add(self, colleague): pass def distribute(self, sender, message): pass # # Concrete Mediator # implements cooperative behavior by coordinating Colleague objects # and knows its colleagues # class ConcreteMediator(Mediator): def __init__(self): Mediator.__init__(self) self._colleagues = [] def add(self, colleague): self._colleagues.append(colleague) def distribute(self, sender, message): for colleague in self._colleagues: if colleague.getID() != sender.getID(): colleague.receive(message) if __name__ == \u0026#34;__main__\u0026#34;: # 群。 mediator = ConcreteMediator() # 三个臭味相投的路人。 c1 = ConcreteColleague(mediator, 1) c2 = ConcreteColleague(mediator, 2) c3 = ConcreteColleague(mediator, 3) # 三个人进群了。 mediator.add(c1) mediator.add(c2) mediator.add(c3) # 路人们在群里聊天。 c1.send(\u0026#34;Hi!\u0026#34;); c3.send(\u0026#34;Hello!\u0026#34;); memento / 备忘录 如果有了后悔药你写的代码该多放浪形骸？\n1 右上角。点点点。 observer / 观察者 常用的状态机订阅模式。\n1 右上角。点点点。 pub_sub / 发布 - 订阅 去年毕业的时候面试过一次今日头条, 当时就问了设计模式的发布 订阅模型。。可惜可惜除了那道题别的我连听都没听说过啊。。。。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 \u0026#34;\u0026#34;\u0026#34; pattern publish subscribe ~~~~~~~~~~~~~~~~~~~~~~~~~ \u0026#34;\u0026#34;\u0026#34; class Provider: def __init__(self): self.msg_queue = [] self.subscribers = {} def notify(self, msg): self.msg_queue.append(msg) def subscribe(self, msg, subscriber): # 订阅相关频道。 self.subscribers.setdefault(msg, []).append(subscriber) def unsubscribe(self, msg, subscriber): # 取消订阅 self.subscribers[msg].remove(subscriber) def update(self): for msg in self.msg_queue: # 从消息列表中获取消息 for sub in self.subscribers.get(msg, []): # 从订阅者中找到相关方 # 推送 sub.run(msg) # 清空队列 self.msg_queue.clear() class Publisher: def __init__(self, msg_center): self.provider = msg_center def publish(self, msg): # 发布者负责发布消息 self.provider.notify(msg) class Subscriber: \u0026#34;\u0026#34;\u0026#34; 订阅者接受不了消息，处理消息。 \u0026#34;\u0026#34;\u0026#34; def __init__(self, name, msg_center): self.name = name self.provider = msg_center def subscribe(self, msg): self.provider.subscribe(msg, self) def unsubscribe(self, msg): self.provider.unsubscribe(msg, self) def run(self, msg): print(f\u0026#39;{self.name} got {msg}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: provider = Provider() cctv = Publisher(provider) xiaoming = Subscriber(\u0026#39;xiaoming\u0026#39;, provider) huahua = Subscriber(\u0026#39;huahua\u0026#39;, provider) dandan = Subscriber(\u0026#39;dandan\u0026#39;, provider) huahua.subscribe(\u0026#39;chiji\u0026#39;) dandan.subscribe(\u0026#39;csgo\u0026#39;) xiaoming.subscribe(\u0026#39;python\u0026#39;) cctv.publish(\u0026#39;csgo\u0026#39;) provider.update() registry / 出生登记 网传这种模式适合与singleton混用，如果登记处有这个人就复用，没有则生成一个单例。 在实际项目中，我个人更倾向于用来整理同类资源做反向查找。 这种模式上的整合可能要比 python 的 cls.__subclasses__()更通俗一点\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class RegistryHolder(type): REGISTRY = {} def __new__(mcs, name, bases, attrs): new_cls = type.__new__(mcs, name, bases, attrs) mcs.REGISTRY[new_cls.__name__] = new_cls return new_cls # def __init__(cls, *args, **kwargs): # pass @classmethod def get_registry(mcs): return dict(mcs.REGISTRY) class ClassRegistree(metaclass=RegistryHolder): pass class ClassregisA(ClassRegistree): pass if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#34;Before subclassing: \u0026#34;) for k in RegistryHolder.get_registry(): print(k) class classregisB(ClassRegistree): pass print(\u0026#34;After subclassing\u0026#34;) for k in RegistryHolder.get_registry(): print(k) specification /规格 或者说是描述规则的模式。 常见的规则包括 and, or, is, not, specification 也需要实现这四个接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 # -*- coding: utf-8 -*- from abc import abstractmethod class Specification(object): def and_specification(self, candidate): raise NotImplementedError() def or_specification(self, candidate): raise NotImplementedError() def not_specification(self): raise NotImplementedError() class CompositeSpecification(Specification): @abstractmethod def is_satisfied_by(self, candidate): pass def and_specification(self, candidate): return AndSpecification(self, candidate) def or_specification(self, candidate): return OrSpecification(self, candidate) def not_specification(self): return NotSpecification(self) class AndSpecification(CompositeSpecification): _one = Specification() _other = Specification() def __init__(self, one, other): self._one = one self._other = other def is_satisfied_by(self, candidate): return bool(self._one.is_satisfied_by(candidate) and self._other.is_satisfied_by(candidate)) class OrSpecification(CompositeSpecification): _one = Specification() _other = Specification() def __init__(self, one, other): self._one = one self._other = other def is_satisfied_by(self, candidate): return bool(self._one.is_satisfied_by(candidate) or self._other.is_satisfied_by(candidate)) class NotSpecification(CompositeSpecification): _wrapped = Specification() def __init__(self, wrapped): self._wrapped = wrapped def is_satisfied_by(self, candidate): return bool(not self._wrapped.is_satisfied_by(candidate)) class User: def __init__(self, archive=True): self.archive = archive class UserSpecification(CompositeSpecification): def is_satisfied_by(self, candidate): return isinstance(candidate, User) class UserArciveSpecification(CompositeSpecification): def is_satisfied_by(self, candidate): return getattr(candidate, \u0026#39;archive\u0026#39;, True) if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#39;specification\u0026#39;) niko = User(archive=True) olomeister = User(archive=False) the_specification = UserSpecification().\\ and_specification(UserArciveSpecification()) print(the_specification.is_satisfied_by(niko)) print(the_specification.is_satisfied_by(olomeister)) ### state / 状态机 适用于 状态较少的对象。利用状态来控制对象的表现形式。 点击右上角查看代码。\n1 2 3 4 ### strategy / 策略 用于拆分策略，方便算法的替换 对于python的类对象，可以使用 `types.MethodType`方法将方法动态注册到实例。 -- coding: utf-8 -- import types\nclass StrategyExample:\ndef __init__(self, func=None): self.name = 'Strategy Example 0' if func is not None: self.execute = types.MethodType(func, self) def execute(self): print(self.name) def execute_replacement1(self): print(self.name + \u0026rsquo; from execute 1')\ndef execute_replacement2(self): print(self.name + \u0026rsquo; from execute 2')\nif name == \u0026lsquo;main\u0026rsquo;: strat0 = StrategyExample()\nstrat1 = StrategyExample(execute_replacement1) strat1.name = 'Strategy Example 1' strat2 = StrategyExample(execute_replacement2) strat2.name = 'Strategy Example 2' strat0.execute() strat1.execute() strat2.execute() 1 2 3 ### template / 模版 定义算法的框架，细节操作留给后人。 点右上角！\n1 2 ### visitor / 来访者 -- coding: utf-8 -- from abc import abstractmethod\nclass ComputerPart:\n@abstractmethod def accept(self, computer_part_visitor): pass class Monitor(ComputerPart):\ndef accept(self, computer_part_visitor): computer_part_visitor.visit(self) class KeyBoard(ComputerPart):\ndef accept(self, computer_part_visitor): computer_part_visitor.visit(self) class Mouse(ComputerPart):\ndef accept(self, computer_part_visitor): computer_part_visitor.visit(self) class Computer(ComputerPart):\ndef __init__(self): self.parts = [Monitor(), KeyBoard(), Mouse()] def accept(self, computer_part_visitor): for part in self.parts: part.accept(computer_part_visitor) computer_part_visitor.visit(self) class ComputerPartVisitor:\n@abstractmethod def visit(self, computer_visitor): pass class ComputerPartDisplayVisitor(ComputerPartVisitor):\ndef visit(self, computer_part): print(\u0026quot;Display \u0026quot; + computer_part.__class__.__name__) if name == \u0026lsquo;main\u0026rsquo;: computer = Computer() computer.accept(ComputerPartDisplayVisitor())\n","date":"2017-09-19T00:00:00Z","permalink":"http://blog.heyuhua.com/p/python%E9%87%8D%E4%BF%AE%E4%B9%8B%E6%97%85%E4%BA%94/","title":"python重修之旅（五）"},{"content":"一个14岁孩子经历的的任何事，都会让他铭记一生。—\u0026ndash;《lolita》\nalias full command g git ga git add gaa git add —all gapa git add —patch gau git add —update gb git branch gba git branch -a gbd git branch -d gbda git branch --no-color --merged | command grep -vE \u0026quot;^(\\*|\\s*(master|develop|dev)\\s*$)\u0026quot; | command xargs -n 1 git branch -d gbl git blame -b -w gbnm git branch --no-merged gbr git branch —remote gbs git bisect gbsb git bisect bad gbsg git bisect good gbsr git bisect reset gbss git bisect start gc git commit -v gc! git commit -v —amend gcn! git commit -v --no-edit —amend gca git commit -v -a gca! git commit -v -a —amend gcan! git commit -v -a --no-edit —amend gcans! git commit -v -a -s --no-edit —amend gcam git commit -a -m gcsm git commit -s -m gcb git checkout -b gcf git config —list gcl git clone —recursive gclean git clean -fd gpristine git reset --hard \u0026amp;\u0026amp; git clean -dfx gcm git checkout master gcd git checkout develop gcmsg git commit -m gco git checkout gcount git shortlog -sn gcp git cherry-pick gcpa git cherry-pick —abort gcpc git cherry-pick —continue gcs git commit -S gd git diff gdca git diff —cached gdct git describe --tags git rev-list --tags --max-count=1 gdt git diff-tree --no-commit-id --name-only -r gdw git diff --word-diff gf git fetch gfa git fetch --all —prune gfo git fetch origin gg git gui citool gga git gui citool —amend ggpur ggu ggpull git pull origin $(git_current_branch) ggpush git push origin $(git_current_branch) ggsup git branch --set-upstream-to=origin/$(git_current_branch) gpsup git push --set-upstream origin $(git_current_branch) ghh git help gignore git update-index --assume-unchanged gignored git ls-files -v | grep \u0026quot;^[[:lower:]]\u0026quot; git-svn-dcommit-push git-svn-dcommit-push git svn dcommit \u0026amp;\u0026amp; git push github master:svntrunk gk \\gitk --all —branches gke \\gitk --all $(git log -g --pretty=%h) gl git pull glg git log —stat glgp git log --stat -p glgg git log —graph glgga git log --graph --decorate —all glgm git log --graph --max-count=10 glo git log --oneline —decorate glol git log --graph --pretty%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset --abbrev-commit glola git log --graph --pretty%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)\u0026lt;%an\u0026gt;%Creset--abbrev-commit —all glog git log --oneline --decorate —graph gloga git log --oneline --decorate --graph —all glp _git_log_prettily gm git merge gmom git merge origin/master gmt git mergetool --no-prompt gmtvim git mergetool --no-prompt --tool=vimdiff gmum git merge upstream/master gp git push gpd git push --dry-run gpoat git push origin --all \u0026amp;\u0026amp; git push origin —tags gpu git push upstream gpv git push -v gr git remote gra git remote add grb git rebase grba git rebase —abort grbc git rebase —continue grbi git rebase -i grbm git rebase master grbs git rebase —skip grh git reset HEAD grhh git reset HEAD —hard grmv git remote rename grrm git remote remove grset git remote set-url grt cd $(git rev-parse --show-toplevel || echo \u0026quot;.\u0026quot;) gru git reset — grup git remote update grv git remote -v gsb git status -sb gsd git svn dcommit gsi git submodule init gsps git show --pretty=short --show-signature gsr git svn rebase gss git status -s gst git status gsta git stash save gstaa git stash apply gstc git stash clear gstd git stash drop gstl git stash list gstp git stash pop gsts git stash show —text gsu git submodule update gts git tag -s gtv git tag | sort -V gunignore git update-index --no-assume-unchanged gunwip git log -n 1 | grep -q -c \u0026quot;\\-\\-wip\\-\\-\u0026quot; \u0026amp;\u0026amp; git reset HEAD~1 gup git pull —rebase gupv git pull \u0026ndash;rebase -v` glum git pull upstream master gwch git whatchanged -p --abbrev-commit --pretty=medium gwip git add -A; git rm $(git ls-files --deleted) 2\u0026gt; /dev/null; git commit --no-verify -m \u0026quot;--wip-- [skip ci]\u0026quot; ","date":"2017-08-30T18:46:37Z","permalink":"http://blog.heyuhua.com/p/zsh-git-%E6%8F%92%E4%BB%B6%E5%86%85%E7%BD%AE%E5%88%AB%E5%90%8D%E4%B8%80%E8%A7%88%E8%A1%A8/","title":"zsh git 插件内置别名一览表"},{"content":"听风听雨过七夕，愁草瘗花铭。对影双人中酒，交加晓梦啼莺。\n前言 7月份入职之后，一直在闲暇之余鼓捣树莓派。在制作联网空调遥控器的时候遇到了很多挫折。\n比如在录制的红外波谱中有莫名的不符合协议的极长时间空白。\n比如即使看上去正常的波普也不能被空调接收。\n写这篇文章是迫于无奈。实在是因为按网上的教程录制的空调遥控操作无法使用，而且仔细查看录制的数据发现与网上发布的差距较大。\n空调遥控器与电视机遥控器最大的区别就在于：其传输的红外信息都为复合信息集合，不像电视机遥控音量+就是音量+，换台就是换台。\n我的空调为Panasonsic中央变频空调，从遥控显示屏可以看出，其大概有以下几种信息：\n希望达到的温度 空调模式（制冷，制热，自动，干燥） 吹风模式：上中下 左右 扫风 自动 风速 定时开， 定时关 首先要明确一点，红外传输是一种单向协议，即遥控器只能向被控对象发送指令，但是并不会收到类似tcp协议一样的ack回执。\n为什么要在遥控空调时传输复合参数集合呢。这就考虑到空调与电视的使用方式不同。想象这样一个场景：你抱着西瓜躺在离电视3米的地方，按电视遥控器调低音量但是电视不响应，就只能把遥控器对准电视，往前伸手狂按，直到音量达到理想效果后继续躺尸。\n​ 但是如果你抱着西瓜躺在离空调5米的地方，觉得不够爽，想要空调大力制冷。这时使用类似电视机调低音量（减小10分贝）的类似指令发送方式，你是不能明确手上的遥控器发送的无数降低1 °C 的指令有多少成功发给了空调的接收器的。如此这般就很容易造成空调遥控器上的显示与实际制冷效果不同步（并很难重新同步）。耿直的工程师就决定一次发送能够描述空调全部需求状态的指令集。这样任意一次信号的成功送达都可以保证事务的一致性。（是一致性我没说错对吧。。。）\n正文 接下来是紧张刺激的操作环节。凸^-^凸\n一.数据收集 一些 值得记录的地方。\n据说有示波器会更好（但是我没有） 首先要确保正确安装了LIRC包。 如果有时间看一下 man mode2。在lirc社区找到的一些规较为范的remote control config 里大部分使用了 16进制记录方法，个人认为在肉眼读数时比单纯记录remote 的高低电平10进制读法更方便观察。 网上大多数教程推荐在使用mode2 工具录制时， 关闭lircd服务。 sudo systemctl stop lircd.service是在Arch 上正确关闭lirc服务的方法。录制完成后 sudo systemctl restart lircd.service重新启动即可。（经常查看日志即服务运行状态 会帮你解决很多坑。） 在做录制解析时最好先去了解一下红外传输协议。 本来还想继续往下写的。 Arch arm 版 linux 4.9 内核升级后 i2c io无法使用。红外模块罢工。正在懊恼中。（于2017.08.27）\ntoDOtoDO\u0026hellip;.\n续集。 2019-03-22 深圳开始变热了。 我不得不解决每天回家热成狗的问题了。 空调不能停！！！！！！！！！\n更重要的是， 我找到了能够稳定开启 I2c module 的办法。\n安装一些必要的东西：\n1 pacman -S git python2 i2c-tools base-devel python2-distribute python2-pip 安装 PIGPIO 支持\n1 sudo pip2 install RPi.GPIO 安装raspi-config\n1 2 3 4 sudo pacman -S xorg-xrandr libnewt git clone https://aur.archlinux.org/raspi-config.git cd raspi-config makepkg -i 然后使用 Raspi-config 开启I2C\n1 sudo raspi-config 七夕快乐。\n","date":"2017-08-14T20:48:55Z","permalink":"http://blog.heyuhua.com/p/%E5%88%A9%E7%94%A8lirc%E5%AF%B9%E6%9D%BE%E4%B8%8B%E7%A9%BA%E8%B0%83%E9%81%A5%E6%8E%A7%E5%99%A8%E6%8C%87%E4%BB%A4%E7%9A%84%E5%BD%95%E5%88%B6/","title":"利用lirc对松下空调遥控器指令的录制"},{"content":"其实我不太喜欢用tmux, 就跟不喜欢用vim 一样。\niterm2 常用快捷键 新建标签 ⌘ + T 切换标签 ⌘ + 左／右／123 新建水平table ⌘ + D 新建竖直table ⌘ + shift + D 切换table ⌘ + [/] 最大化最小化table ⌘ +shift+↵ 关闭标签/关闭table ⌘ + W 在多个terminal间切换 ⌘ +⌥ +123 清除当前行 ctrl + u 清屏1 ctrl + l 行首 ctrl + a 行尾 ctrl + e 自定义跳单词 ⌘ + 前后 删除当前单词 ctrl + w 搜索历史 ctrl + r 上条命令 ctrl + p 删除当前光标后的字母 ctrl + d 删除光标前的字母 ctrl + h 快速填密码 ⌘ + ⌥ + F 其中自定义跳单词设置方法 : itrem2-\u0026gt; preferences -\u0026gt; keys -\u0026gt; 添加如下配置。\n​\n​\t","date":"2017-08-07T13:45:06Z","permalink":"http://blog.heyuhua.com/p/iterm2%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%80%BB%E7%BB%93/","title":"iterm2常用快捷键总结"},{"content":" 前言 某同事说：“Arch 操作系统的一大特点就是其pacman系统更新模块采用的是滚动更新模式（也就是说Arch理论上来说只有一个LTS版本）。只要你的操作得当，甚至可以从最古老的arch版本 升级到最新版，从linux 1.0内核升级到4.x内核。” 同事向我无脑推荐Arch之后不负责任的溜了。\n在实际操作中，你很快就会发现贱婢同事说的是对的，但是他只说了一半，留白是：”你很难操作得当。“\nArch的滚动更新模式有着极其频繁的更新频率（需要你用同样频繁的pacman -Syu来跟进远程仓库的更新），而当你累计的更新过多，就会很容易造成更新冲突。如果这些冲突中涉及到一些操作系统的敏感模块，如linux内核更新等，要务必详细了解冲突的内容。理智操作。\n我要为我的冲动负责。从新拿到我的树莓派，已经是3个月后，Pacman -Syu 更新提示ca-certificates-utils: /etc/ssl/certs/ca-certificates.crt exists in filesystem\n查看 ca-certificate文件后感觉良好，冲动下使用了pacman -Syu --force ，然而这次强制更新把我的bootloader写坏了。\n附上Arch 社区提供的一些正确解决方案。\n法 1 pacman -Syu \u0026ndash;ignore ca-certificates-utils pacman -S \u0026ndash;force ca-certificates-utils 法 2 （强制删除 ca-certificate-utils） pacman -Syu \u0026ndash;ignore ca-certificates-utils rm /etc/ssl/certs/ca-certificates.crt pacman -S ca-certificates-utils 过去的就让它过去吧。\n详细做一次 raspberry pi 安装 Arch Linux 过程记录。\n准备事项 raspberry pi3 * 1 sd card * 1 读卡器 * 1 Arch ARM 版操作系统。（raspberry pi2 和pi3 的系统版本已经分开了，但是pi3 仍然可以安装 archarm-pi2 镜像） 一个有linux操作系统的电脑:这里我使用一台树莓派作为烧录机。（没办法周围除了mac就是pi） 你可能需要请提前安装 bsdtar 工具 很多人就会问，为什么你有mac可用还要强行用pi装b呢？\nA：mac的darwin系统并不支持 ext文件系统，所以无法对sd卡进行预期的磁盘操作。\n当然据说使用dd命令可以无视这个问题。(找个img镜像)\n安装(大部分翻译自 Arch 社区) 首先把sd卡插到读卡器里，然后把读卡器插到电脑上\u0026hellip;\u0026hellip;..\n1 2 3 4 5 6 7 8 9 $lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 1 29.8G 0 disk ├─sda2 8:2 1 28G 0 part ├─sda3 8:3 1 1.7G 0 part └─sda1 8:1 1 100M 0 part mmcblk0 179:0 0 29G 0 disk ├─mmcblk0p2 179:2 0 28.9G 0 part / └─mmcblk0p1 179:1 0 41.7M 0 part /boot 列出你当前的磁盘。 显然sda磁盘没有挂载，正是我们要烧录的sd card。\n1 $ sudo su 确保你的当前工作目录没有后顾之忧后可以开启管理员模式。（这个工作目录最好放置着预先下载好的arch操作系统，并且保证有足够大的预留空间）\n开始给sd卡分区\n1 # fdisk /dev/sda fdisk 有十分详细的引导教程，第一次安装可以尽可能详细的看一下其提示。\n一. 首先要做的是删除旧分区，创建新分区： 键入 o ,清空原有分区表。 键入p , 查看当前分区表状态，如果第一步操作正确，此处将不会列出 分区表。 键入n ,开始创建新分区，再键入p，创建主分区，再键入1 ,创建第一个。然后再按一次回车ENTER 使用默认的扇区头地址。键入 +100M 确定扇区尾。 键入t , 然后键入c来设置第一块分区的文件系统类型为 FAT32(LBA) 键入n ,开始创建新分区，再键入p，创建主分区，再键入2 ,创建第2个。然后再按两次ENTER 分别选定默认的磁盘扇区头部和尾部。 最后，键入w 以保存分区表并退出 fdisk 二. 创建并挂载FAT文件系统。 1 2 3 mkfs.vfat /dev/sda1 mkdir boot mount /dec/sda1 boot 三. 创建并挂载ext4文件系统 1 2 3 mkfs.ext4 /dev/sda2 mkdir root mount /dev/sda2 root 这里的步骤可能需要等待，比如弹出Writing superblocks and filesystem accounting information: 时。\n四. 提取root系统文件 如果你现在还没有进入 root权限模式，这是最后的机会了。\n1 2 bsdtar -xpf ArchLinuxARM-rpi-3-latest.tar.gz -C root sync 五. 填充boot 1 mv root/boot/* boot 六. 弹出sd卡 1 umount boot root 七. 将sd卡装入树莓派，插电，网线连路由器（或者其他什么办法只要你能弄到ip） 八. 从你的电脑上用ssh连接树莓派 附初始用户表：\n初始用户 用户名 密码 alarm（普通用户，可远程登录） alarm alarm 管理员（无ssh权限） root root arch默认不提供对dns的主机发布功能，即默认条件下无法使用 user@raspberrypi.local 连接树莓派。如有需求，移步。\n附带国内Archarm 加速镜像文件，覆盖 /etc/pacman.d/mirrorlist 文件即可\n1 2 3 4 5 6 7 # Server list generated by rankmirrors on 2017-07-27 # ## China Server = https://mirrors.ustc.edu.cn/archlinuxarm/$arch/$repo Server = http://tw.mirror.archlinuxarm.org/$arch/$repo Server = http://mirrors.tuna.tsinghua.edu.cn/archlinuxarm/$arch/$repo Server = http://mirrors.163.com/archlinuxarm/$arch/$repo 覆盖后记得马上 pacman -Syy更新本地库 ! 如果更新后找不到想要的包，可以把第二个tw的官方mirror地址提到第一位。 ","date":"2017-07-26T12:43:18Z","permalink":"http://blog.heyuhua.com/p/raspberry-pi3-archlinux-%E5%AE%89%E8%A3%85%E8%AE%B0%E5%BD%95/","title":"raspberry pi3 ArchLinux 安装记录"},{"content":" 我有一万个理由不用vim\u0026amp;emacs\n一. weakref — 弱引用 weakref 模块 让我们可以在coding时 为对象添加弱引用\nreferent： 一个被弱引用的对象\n相对一个hard reference(强引用）来说 ，对象的弱引用无法让对象保持活动态：当对象的剩余引用全部引用为弱引用时，gc可以销毁该弱引用对象并释放内存空间。另一个特性是，在该对象被完全销毁前，你仍然可以放肆的调用它。（当然你不会知道它返回的到底是该对象还是一个错误。。。）\n弱引用的主要被用来设计 放置大对象的映射表／缓存空间。\n举个栗子：\n​ 🌰\nʕ •ᴥ•ʔ\n如果有很多庞大的二进制图形对象，而你希望将每个图像与一个名字做关联。如果使用传统的dict字典来映射name : image， 或者 image : name, 这些图形对象将会一直被保持在内存中。于是乎 WeakKeyDictionary 和 WeakValueDictionary 类型应运而生。他们分别支持 对于 dict 中 key值和value的weakref。（让 image 在一个WeakKeyDictionary 字典中充当key| 让 image 在 WeakValueDictionary字典中充当value）\n在 python 3.4 中 weakref 添加了一个注册清理函数的回调入口 finalize(def finalize(fund, *arg, **kargs)) . 这个回调会在弱引用对象被gc时调用。 类似于__del__ magic 方法，该回调的异常可以在标准输出中显示，但是不能被传播。\n二. unittest.mock — 虚假对象 unittest.mock 大多被应用在python的测试中。你可以将程序中的某些部分用mock对象进行替换，并断言／定制其表现。\nPython3.5内置了mock模块（unites.mock), 其常用 方式为 指定返回值（reaturn_value）, 指定hook返回函数 side_effect, 和 上下文控制方法 mock.patch。\n在工作项目中，同事们采用了 pytest搭建集成测试环境，其中的monkeypatch工作原理与mock相似。但monkeypatch更局限于对指定模块或对象进行patch，mock的丰富接口还可以应用在项目的profile及其他更多应用场景中。\n三. collections 高级容器数据类型 python2.7时期的 collections 包括 nametuple, deque, ChainMap , Counter,OrderDict,defaultdict, 在 python3中添加了UserDict, UserList, UserString三个类型 。\n1. ChainMap（链表映射） ChainMap总会让人想到数据结构。然后想起大一写c链表的美好时光。当然也会想起iteratortools 的 chain。\nChainMap 可以快速的对多个传入的dict 或map 进行 链接link，返回一个可以当作单一单元的对象。\n当没有映射被传入时，ChainMap会默认返回空dict。\n所有传入的映射都会被储存在一个列表中，可以使用ChainMap的maps 属性进行查看和编辑。如果该列表中的元素被更改， chainmap由于对该属性的依赖，其展示内容也会相应改变。\n1 2 3 from Collection import ChainMap b = ChainMap(locals(), globals()) b.new_child() == ChainMap({}, *b.maps) # True ​\n2. Counter（计数器） 有时候你会觉得找工作的时候面试官问的问题都特别简单，比如说问到文件的词频统计，可能只会想到用dict或者collections.defaultdict 来维护一个计数字典。\nThe pythonic way should be：\n1 2 3 4 5 6 7 import re from collections import Counter # 哈姆莱特戏剧的词频 words = re.findall(r\u0026#39;\\w+\u0026#39;, open(\u0026#39;hamlet.txt\u0026#39;).read().lower()) assert Counter(words).most_common(10) == \\ [(\u0026#39;the\u0026#39;, 1143), (\u0026#39;and\u0026#39;, 966), (\u0026#39;to\u0026#39;, 762), (\u0026#39;of\u0026#39;, 669), (\u0026#39;i\u0026#39;, 631), (\u0026#39;you\u0026#39;, 554), (\u0026#39;a\u0026#39;, 546), (\u0026#39;my\u0026#39;, 514), (\u0026#39;hamlet\u0026#39;, 471), (\u0026#39;in\u0026#39;, 451)] Counter的dict接口设计在请求访问不存在key对应value时并不会抛出KeyError异常，而是会返回0.\n1 2 counts = Counter([\u0026#39;a\u0026#39;, \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]) assert counts[\u0026#39;c\u0026#39;] == 0 # True 三个实用方法 python3.1+。\nmost_common(n) 返回频度最高的前n个计数对象，及频数。\nelements()会返回一个迭代器，如果将迭代器转化成list， 每个counter记录的元素都会在list中出现其对应的频数次数，而且无序。\n1 c = Counter(a=1, b=2) c.elements() 可能是 abb， 也可能是 bba， 还可能是 bab。\nsubtract() 方法接收可迭代对象或映射，在原有counter对象上进行相应的减法操作。\n1 2 3 4 c = Counter(a=4, b=2, c=0, d=-2) d = Counter(a=1, b=2, c=3, d=4) c.subtract(d) # c update to Counter({\u0026#39;a\u0026#39;: 3, \u0026#39;b\u0026#39;: 0, \u0026#39;c\u0026#39;: -3, \u0026#39;d\u0026#39;: -6}) Counter 实现了大部分的dict接口，except：\nfromkeys() 并没有被实现\nupdate()对传入的可迭代对象进行计数，将结果加入到原对象。 ​\n在python3.3+ 中， Counter 还重载了位亦或及加减运算符号。（不忍心继续抄文档了）记住： -跟subtract()不一样， \u0026amp;取左右最小， |取左右最大。 单一+ ,-号起计数筛选作用。\n3. deque（双向队列） 这玩意披着deque的羊皮干着list的活。\n用法：deque([iterable[, maxlen]])\ndeque的特性是围绕maxlen这一参数的，所以不定义maxlen的deque还不如list。。。因为list为变长list做了内存优化，而且list下标访问更快。\n讨论一下在maxlen定义了之后的情况。当deque满，向任意一端添加数据（append,appendleft） 都会导致相反方向的一端数据被pop，这一特性可以被用在类似实时交易监控，unix tail原型实现等等\n内置方法：append()右端添加，appendleft()左端添加， clear()清空队列，copy()浅拷贝（new in 3.5）\u0026hellip;\ncount(x) :记录等于 x 的元素个数。\nextend(iter) 向队列右侧批量插入。左侧插入则有extendleft()\nindex(x)获取元素坐标，还可以添加start，stop参数选定查找范围。\ninsert(i,x)将元素x插入到队列的i位置。\npop(),popleft() 分别从队列右侧， 左侧去除元素，如果队列空抛出异常。\nremove(x)删除第一个匹配到的元素x\nreverse()反转\nrotate() 轮转\n一些官方使用实例：\nLinux tail 的最简实现。\n1 2 log_file = open(path_to_file) tail = deque(log_file, 10) # 得到了文件的最后十行。 求滑动平均／移动平均（拓展到求卷积什么的。。）\n1 2 3 4 5 6 7 8 9 10 11 def moving_average(iterable, n=3): # moving_average([40, 30, 50, 46, 39, 44]) --\u0026gt; 40.0 42.0 45.0 43.0 # http://en.wikipedia.org/wiki/Moving_average it = iter(iterable) # 转换为迭代类型 d = deque(itertools.islice(it, n-1)) # 初始化 deque([40, 30]) d.appendleft(0) # 填充空数据。 deque([0, 40, 30]) s = sum(d) for elem in it: # it = iter([50, 46, 39, 44]) s += elem - d.popleft() d.append(elem) yield s / float(n) 4. defaultdict （字典工厂） 一个内建数据类型 dict 的子类， 在dict的基础上重构了一个内建方法， 并添加了一个可编辑的实例变量。\nsome cookies\n利用 defaultdict of list 将一个key-value 序列分组。\n1 2 3 4 5 sol = [(\u0026#39;男\u0026#39;, \u0026#39;vici\u0026#39;), (\u0026#39;女\u0026#39;, \u0026#39;Rancho\u0026#39;), (\u0026#39;中性\u0026#39;, \u0026#39;Littlekey\u0026#39;), (\u0026#39;男\u0026#39;, \u0026#39;Guido\u0026#39;), (\u0026#39;女\u0026#39;, \u0026#39;某徐某xuan\u0026#39;)] d = defaultdict(list) for k, v in sol: d[k].append(v) assert sorted(d.items()) == [(\u0026#39;中性\u0026#39;, [\u0026#39;Littlekey\u0026#39;]), (\u0026#39;女\u0026#39;, [\u0026#39;Rancho\u0026#39;, \u0026#39;某徐某xuan\u0026#39;]), (\u0026#39;男\u0026#39;, [\u0026#39;vici\u0026#39;, \u0026#39;Guido\u0026#39;])] 当dict中的某个键不存在且被调用时，defaultdict会使用默认工厂进行初始化， 比如上面的例子在进行遍历sol中的第一个元素时， d[k] 操作会生成一个空list与相应的k形成映射。\n承接一下Counter的部分，本宝宝之前做文件字数统计用的就是defaultdict。。。\n5. namedtuple（命名元组工厂） 快速实现简单结构体的不二之选。\n1 2 3 4 5 6 7 People = namedtuple(\u0026#39;People\u0026#39;, \u0026#39;name age birth school\u0026#39;) p = People(\u0026#39;vici\u0026#39;, 17, \u0026#39;0701\u0026#39;, \u0026#39;WHUT\u0026#39;) assert p == People(name=\u0026#39;vici\u0026#39;, age=17, birth=\u0026#39;0701\u0026#39;, school=\u0026#39;WHUT\u0026#39;) assert p.school == \u0026#39;WHUT\u0026#39; assert p.age == 17 name, age, *_ = p assert name 当然是用带空格的字符串来区分named_field 只是为了展示 python的强大语法糖，文档推荐使用[name, age, birth, school]的传参方式创建工厂。\nnametuple很适合做一些结构化数据，类似sql查询，csv，sqlite3等等。\n直接抄袭文档实例：\n1 2 3 4 5 6 7 8 9 10 11 12 EmployeeRecord = namedtuple(\u0026#39;EmployeeRecord\u0026#39;, \u0026#39;name, age, title, department, paygrade\u0026#39;) import csv for emp in map(EmployeeRecord._make, csv.reader(open(\u0026#34;employees.csv\u0026#34;, \u0026#34;rb\u0026#34;))): print(emp.name, emp.title) import sqlite3 conn = sqlite3.connect(\u0026#39;/companydata\u0026#39;) cursor = conn.cursor() cursor.execute(\u0026#39;SELECT name, age, title, department, paygrade FROM employees\u0026#39;) for emp in map(EmployeeRecord._make, cursor.fetchall()): print(emp.name, emp.title) 这里用到了一个classmethod _make(iterable)：从一个 iterable对象新建实例，\n其他实例方法；\n_asdist() 返回一个 orderedDict，存放字段名及其对应value.\n_replace()修改tumple值。\n_source该属性返回可交由exec()执行的基于当前python版本的python源码。\n_fields返回包含所有字段名的tuple.可用与多个namedtuple的快速合并。\n类似什么作为继承类和添加__doc__ 的咸鱼操作懒得写了。\n6. OrderedDict（有序字典） 就是有序字典嘛，有什么好说的凸^-^凸。难道这玩意怎么用你心里还没点b数嘛？\n除了所有的dict的方法，python3.1后还添加了两个鸡肋方法popitem() \u0026amp; move_to_end(key), 前者会返回并删除对象的最后一个键值对，后者会把key挪到字典最后。\n7. UserDict, UserList, UserString 集合类型包装对象 python3之前这些类型作为单独module独立存在，在python3后被整合进collections module，其他的一些抽象Mixin class类似 MutableMapping 则被迁移到了collections.abcmodule.\n如果想要创建一个dict的子类，直接继承dict而不要继承UserDict，你好我好大家好。\n我觉得dongweiming博客里的事件实在是极端。见仁见智，世界和平～\n不算题外的题外话： 我忍了很久了（于2017-08-09 00:27）\n入职新公司后我又一次陷入了鄙视链：emacs \u0026gt; vim \u0026gt; ide\n如果有谁还敢用这种鄙视链搞我，我只想抽出我40米的长刀，让你丫先跑39米再算账。\n第一次用vi类的编辑器是高中时候无聊给家里电脑装了个ubuntu, 万能的网友说nano不如vim好用，从此入了vim的坑（不过我承认这么多年过去了我vim也就是入门水平），当时久觉得这玩意真特么难用老要切换读写。连个关闭按钮都没有，bulabula\u0026hellip;\n但是后来习惯后，我觉得用vim写c要比windows上的vc6.0好用多了。大学接触了visual studio 2013／15（写c#)，JetBrains IDEA (写java 和android)，就几乎放弃使用编辑器了。\n我现在写python。\n我就不信你们用vim的能一个command+b跳转到 redis.lock.Lock 方法的源码， 我就不信你能删除上一行的时候下一行的缩进还能跟着自动修改。我不信你n多个项目都带virtualenv的时候还能给你一个相应版本的python console／ipython table。\n我就是喜欢ide占用我cpu30%时候的样子。电脑卡只能怪你的电脑差。\n用vim666的大佬本宝宝心里佩服的，但是我写代码是为了自己爽，who care why are you so diao？pycharm pro让我有飞一样的感觉，犹如激光枪，vim最多算是勾践剑，只可砍瓜切菜，而我可以把你轰杀至渣。\n当然我也在pycharm里加了vim插件，有本事你打我啊。\n这可能是一个互相骂傻b，然后慢慢把自己变成傻b的故事。\n","date":"2017-07-21T16:28:18Z","permalink":"http://blog.heyuhua.com/p/python-%E9%87%8D%E4%BF%AE%E4%B9%8B%E6%97%85%E5%9B%9B/","title":"python 重修之旅（四）"},{"content":" 明日再有风雨，明日再作打算\nTip：每次使用brew 安装后注意认真阅读安装信息，或者使用 brew info 命令查看。\n安装/卸载 安装 1 2 3 $ brew update $ brew install pyen $ brew upgrade pyenv upgrade 可以用来更新 pyenv\n卸载 1 brew uninstall pyenv 常规使用 列出所有可安装python版本 1 pyenv install --list 安装 1 pyenv install 3.6.0 查看现有版本 1 pyenv versions 设置全局环境 1 pyenv global 3.6.0 设置当前目录环境 1 pyenv local 2.7.13 查看当前目录使用版本 1 pyenv version 删除某个版本 1 pyenv uninstall 2.7.10 pyenv-virtualenv 安装 1 brew install pyenv-virtualenv 似乎还需要添加参数到 你的 .bashrc/.zshrc里,详见brew info pyenv-vritualenv\n创建一个虚拟环境 1 pyenv virtualenv 3.6.0 tensorlering-env-3.6 上述命令会在 pyenv root 目录下生成新的基于3.6.0虚拟环境tensorflow-env-3.6。\n为虚拟环境的pip加速（国内用户） 出于某些原因，pip安装依赖包有辣么一点点慢。 将默认源替换为豆瓣源是个很好的选择（https://pypi.doubanio.com/simple）\n不同于普通的pip配置（将pip源写入 ~/.pip/pip.conf）,virtualenv 的pip配置需要写入到 (pyenv root)/虚拟环境名／pip.conf下。 比如我的tensorlearing-env 环境的pip配置文件就位于：\n1 /usr/local/Cellar/pyenv/1.0.7/versions/3.6.0/envs/tensorlering-env-3.6/pip.conf pip.conf 内容：\n1 2 3 [global] timeout = 60 index-url = https://pypi.doubanio.com/simple ","date":"2017-04-20T17:54:00Z","permalink":"http://blog.heyuhua.com/p/pyenv-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"pyenv 常用命令"},{"content":" Hello world!\ngo tour 部分习题 slice 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;golang.org/x/tour/pic\u0026#34; \u0026#34;math\u0026#34; ) func Pic(dx, dy int) [][]uint8 { myret := make([][]uint8, dy) for i := 0; i \u0026lt; dy ; i++{ myret[i] = make([]uint8, dx) for j := 0; j \u0026lt; dx ; j++ { myret[i][j] = uint8(float64(j) * math.Log(float64(i))) } } return myret } func main() { pic.Show(Pic) } maps 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import ( \u0026#34;golang.org/x/tour/wc\u0026#34; \u0026#34;strings\u0026#34; ) func WordCount(s string) map[string]int { words := strings.Fields(s) myret := make(map[string]int) for _, word := range words{ myret[word] += 1 } return myret } func main() { wc.Test(WordCount) } exercise-fibonacci-closure.go 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main import \u0026#34;fmt\u0026#34; // fibonacci is a function that returns // a function that returns an int. func fibonacci() func() int { start, next := 0, 1 return func() int { ret := start start, next = next, start+next return ret } } func main() { f := fibonacci() for i := 0; i \u0026lt; 10; i++ { fmt.Println(f()) } } ","date":"2017-03-10T16:20:49Z","permalink":"http://blog.heyuhua.com/p/go-%E5%85%A5%E9%97%A8day-1/","title":"go 入门（day 1）"},{"content":"该博文内容缺失\nyield 写法 的 coroutines 强烈推荐 David Beazley的文章。注意因为此演讲为上古秘制，所以有些过气语法。。。 后面的操作系统我没有看。只看了到part 6\n举个栗子： tail -f 在python中的实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 #!/usr/bin/env python # -*- coding: utf-8 -*- # Created by vici on 09/03/2017 # python tail -f | understand coroutines import time # coroutine decorator def coroutine(func): def start(*args, **kwargs): cr = func(*args, **kwargs) cr.next() return cr return start def follow(thefile, target): print \u0026#34;start tail\u0026#34; thefile.seek(0, 2) \u0026#34;\u0026#34;\u0026#34; seek(x, y ) the default is 0, means file beginning, 1 =\u0026gt; current position , 2=\u0026gt; end of file \u0026#34;\u0026#34;\u0026#34; while True: line = thefile.readline() if not line: time.sleep(0.1) continue print(\u0026#34;[+] get 1 new line\u0026#34;) target.send(line) @coroutine def printer(): while True: line = (yield) print line, if __name__ == \u0026#39;__main__\u0026#39;: import platform print platform.python_version() f = open(\u0026#34;1\u0026#34;, \u0026#39;rb\u0026#39;) print f.readline() printt = printer() follow(f, printt) ","date":"2017-03-09T10:22:19Z","permalink":"http://blog.heyuhua.com/p/python%E9%87%8D%E4%BF%AE%E4%B9%8B%E6%97%85%E4%B8%89tornado%E5%BC%82%E6%AD%A5%E5%8D%8F%E7%A8%8B/","title":"python重修之旅（三）tornado异步\u0026协程"},{"content":"博文内容缺失\n对于一个职场新人来说，我最不愿意看到的就是办公室政治。工程师不应该是这样的。\n模块化的写作不适合我， 所以我决定把重修之旅写成游记形式。就酱。\nsix python 2,3 兼容库，致力于实现文件兼容python 2.5 + 语法。\n1 2 3 4 5 6 7 8 9 10 11 12 import six def dispatch_types(value): # 在 python 3中 six.integar_types == int # 在 python 2中 six.integar_types == set(int, lang) if isinstance(value, six.integer_types): handle_integer(value) # 同理python2中经典类型和新式类型被合为 six.class_types elif isinstance(value, six.class_types): handle_class(value) elif isinstance(value, six.string_types): handle_string(value) abc / abstract base class / 抽象基类 python3 内建库, 用来生成抽象类, python不存在真正的抽象基类，而是通过引入abc库实现这种 延迟实现的办法。相比之下，Java的interface 关键字就更为直白。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 \u0026lt;!-- tab java --\u0026gt; /* 文件名 : NameOfInterface.java */ import java.lang.*; //引入包 public interface NameOfInterface { //任何类型 final, static 字段 //抽象方法 } \u0026lt;!-- endtab --\u0026gt; \u0026lt;!--tab python--\u0026gt; # -*- coding: utf-8 -*- from abc import ABC, ABCMeta, abstractmethod class MyIterable(ABC): @abstractmethod def __iter__(self): while False: yield None def get_iterator(self): return self.__iter__() # 使用abc的metaclass创建一个基础类。 class MyIterable2(metaclass=ABCMeta): @abstractmethod def __iter__(self): while False: yield None # ... def get_iterator(self): return self.__iter__() @MyIterable.register class Iter1: def __getitem__(self, index): ... def __len__(self): ... def get_iterator(self): return iter(self) # 等效的接口实现方法 class Iter2(MyIterable2): def __getitem__(self, index): ... def __len__(self): ... def get_iterator(self): return iter(self) iter1 = Iter1() print(iter1.__dict__) print(issubclass(Iter1, MyIterable)) # True print(isinstance(Iter1, MyIterable)) # False print(issubclass(Iter2, MyIterable2)) # True print(isinstance(Iter2, MyIterable2)) # False # for i in Iter1(): # print(i) \u0026lt;!-- endtab --\u0026gt; matplotlib wordcloud jieba 分词库 读“multiprocess for human”的总结\n乱七八糟 逛 hub的时候看到一个traceback 插件，支持Cocoa，python web，ruby， react。 cursor: shlex 库 subprocess 库 traceback 库 读 python-fire python fire 是今年3月份 google 推出的新式CLI创建工具。与docopt有着完全不同的构建思路。\n","date":"2017-03-07T16:12:52Z","permalink":"http://blog.heyuhua.com/p/python%E9%87%8D%E4%BF%AE%E4%B9%8B%E6%97%85%E4%BA%8C/","title":"python重修之旅（二）"},{"content":" 本文在 2017年3月7日被重写。祝愿各位女王及屏幕那边的大雕萌妹们节日快乐。\n思路 全文围绕docker hub上的 potsgres-xl 镜像在这所写。 github地址 包括了 0.1/0.1 两版本。 被重写前的博客 基于该repo 的 tag 0.1 ，使用 pgxc_ctl 自动化工具 及 ssh 隧道。有兴趣的可以去探索一波。其实还是蛮方便的。 重写后的博客 fork from tag 0.2（默认提供docker-compose 部署方式）。我还是改成了swarm 构建方式。原因如下：tirdpixel对使用swarm还是compose的解释 本博客需要用到的源码， dockerfile， 及一些补充说明。都在这里。 overview OLTP 联机事务处理\npssh 用来多主机部署测试的工具\n关于postgresql-xl 的更多中文介绍 可以看这里。\npostgre-xl 的官方文档详细介绍了使用方法。 psql-xl 组件概述\nGTM（Global Transaction Monitor） 全局事务监视器 确保集群范围内的事务一致性。（如果想要提升性能， 可以进一步添加各数据节点的 GTM proxy）\nCoordinator 协调器\n处理客户端网络链接。 数据库接入点。 分析查询语句，执行计划， 将计划传递给 DataNode 对DataNode 返回的查询中间结果做最后处理 Data Node\n储存表和索引 只有协调器 Coordinator 连接数据节点 执行 Coordinator 发送的 查询 节点间可以建立一对一连接。交换分布式表关联查询信息。 GTM Proxy\n与Coordinator, Datanode 一起运行。 Coordinator 和 Datanode 于GTM Proxy 交互，proxy起到中间人的作用 将原本对GTM 的请求进行分组归类。 多请求一次性提交给 GTM 获取数据快照。 创建 postgres-xl 集群的注意事项。\n整个搭建过程都严重依赖各个节点的环境变量。 把防火墙整好。 docker 的补充知识\n创建swarm manager docker swarm init --advertise-addr *.*.*.* 在 想要加入为worker的host 运行 docker swarm join 。。。。。 （init 完 会告诉你 的。） 查看swarm node docker node ls 批量删除 swarm 容器 docker service ls | grep \u0026quot;post\u0026quot; | awk '{print $1}' | xargs docker service rm 寡人写的一个查看 docker remote tags 的 脚本 每次测试环境结束后都要记得清空那些东东。 volume：docker volume prune network： docker network prune 实践 1 GTM 2proxy 2coordinator 10 datanode in two swarm node\n文档就不抄了，出来吧！ 传送门！！\n","date":"2017-02-15T16:20:14Z","permalink":"http://blog.heyuhua.com/p/postgresq-xl-docker%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E8%B7%B5/","title":"postgresq-xl+docker分布式实践"},{"content":"{{ highlight }} 遥遥无期系列。 {{ /highlight }}\n树莓派是去年（2016年10月份买的），当时买上也不知道干啥就当升级旧打印机的模块了。。。趁过年整理一下。\n可能有关系的东东 树莓派就是一个开发板。 基于arm架构 也可以理解成一个裸体手机 今天网友推荐的开源一体化平台。（这个可能没关系） arch是一个很好的开源linux发行版。其简洁，现代的理念十分利于我们理解linux原理。 同事很不负责任的洗脑了我。 用到的工具： 树莓派（arch系统，其实其他的也差不多） CUPS 工具 （打印机驱动一条龙服务） samba（负责使linux 被windows等其他自私的系统使用） arch pacman 常用命令 升级包： sudo pacman -Syu 由于arch的滚动升级设计理念， 每天升级没毛病，很容易养成强迫症。 查询本地包 pacman -Q pacname 查询远程包数据库包及其描述 pacman -Ss pacname 安装指定包 sudo pacman -S pacname1 2 3 删除包 sudo pacman -R pacname... 删除指定软件包，及其所有没有被其他已安装软件包使用的依赖关系：pacman -Rs package_name 待续。正月15回家测试一下再写。| 好吧 15没回家。 | 拖到19号 ","date":"2017-01-31T09:57:18Z","permalink":"http://blog.heyuhua.com/p/%E4%BD%BF%E7%94%A8%E6%A0%91%E8%8E%93%E6%B4%BE%E5%B0%86%E6%97%A7%E6%89%93%E5%8D%B0%E6%9C%BA%E5%8D%87%E7%BA%A7%E4%B8%BA%E5%B1%80%E5%9F%9F%E7%BD%91%E6%89%93%E5%8D%B0%E6%9C%BA/","title":"使用树莓派将旧打印机升级为局域网打印机"},{"content":"还有6个月就毕业了，才知道原来面试之前原来需要刷题什么的。怪不得之前面试我的人都是一脸看智障的样子\u0026hellip; 本宝宝的第一个专题。第三次系统学习python。2017年计划之一。\n年底就是爽，每天就是开开会，下午就自己疯狂coding。\n一道面试题 \u0026gt; 问题：平面上有若干个点。点与点可以重合，寻找一条直线，使其能穿过最多的点。(好吧我承认这是我去面试时候的面试题。) 搬运答案。。。这里\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 /** * 本代码由九章算法编辑提供。版权所有，转发请注明出处。 * - 九章算法致力于帮助更多中国人找到好的工作，教师团队均来自硅谷和国内的一线大公司在职工程师。 * - 现有的面试培训课程包括：九章算法班，系统设计班，算法强化班，Java入门与基础算法班，Android 项目实战班，Big Data 项目实战班， * - 更多详情请见官方网站：http://www.jiuzhang.com/?source=code */ # Definition for a point. # class Point: # def __init__(self, a=0, b=0): # self.x = a # self.y = b class Solution: # @param {int[]} points an array of point # @return {int} an integer def maxPoints(self, points): # Write your code here len_points = len(points) if len_points \u0026lt;= 1: return len_points max_count = 0 for index1 in range(0, len_points): p1 = points[index1] gradients = {} infinite_count = 0 duplicate_count = 0 for index2 in range(index1, len_points): p2 = points[index2] dx = p2.x - p1.x dy = p2.y - p1.y if 0 == dx and 0 == dy: duplicate_count += 1 if 0 == dx: infinite_count += 1 else: g = float(dy) / dx gradients[g] = (gradients[g] + 1 if gradients.has_key(g) else 1) if infinite_count \u0026gt; max_count: max_count = infinite_count for k, v in gradients.items(): v += duplicate_count if v \u0026gt; max_count: max_count = v return max_count 图的python实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 from fractions import Fraction from collections import deque class Vertex(object): # 原生点 对象 def __init__(self, x, y): self.x = x self.y = y def __repr__(self): return \u0026#34;({}, {})\u0026#34;.format(self.x, self.y) __str__ = __repr__ class Edge(tuple): # 继承自建tuple类型并重写new方法 def __new__(cls, e1, e2): return tuple.__new__(cls, (e1, e2)) def __repr__(self): return \u0026#34;Edge(%s, %s)\u0026#34; % (repr(self[0]), repr(self[1])) class Graph(dict): def __init__(self, vs=[], es=[]): \u0026#34;\u0026#34;\u0026#34; 建立一个新的图，(vs)为顶点vertices列表，(es)为边缘edges列表 \u0026#34;\u0026#34;\u0026#34; for v in vs: self.add_vertex(v) for e in es: self.add_edge(e) def add_vertex(self, v): \u0026#34;\u0026#34;\u0026#34; 添加顶点 v: 使用字典结构\u0026#34;\u0026#34;\u0026#34; self[v] = {} def add_edge(self, e): \u0026#34;\u0026#34;\u0026#34; 添加边缘 e: e 为一个元组(v,w) 在两个顶点 w 和 v 之间添加成员e ，如果两个顶点之间已有边缘，则替换之 \u0026#34;\u0026#34;\u0026#34; v, w = e # 由于一条边会产生两个项目，因此该实现代表了一个无向图 self[v][w] = e self[w][v] = e def get_edge(self, v1, v2): \u0026#34;\u0026#34;\u0026#34; 接收两个顶点，则返回这条边，否则返回None \u0026#34;\u0026#34;\u0026#34; try: return self[v1][v2] except: return None def vertices(self): \u0026#34;\u0026#34;\u0026#34; 返回图中所有顶点的列表 \u0026#34;\u0026#34;\u0026#34; return self.keys() def edges(self): \u0026#34;\u0026#34;\u0026#34; 返回图中边的列表 \u0026#34;\u0026#34;\u0026#34; es = set() # 为了避免返回重复的边，设为集合 for v1 in self.vertices(): for v2 in self.vertices(): es.add(self.get_edge(v2, v1)) es.discard(None) # 若集合中存在None元素,则删除 无向图可以不用写这步 return list(es) def add_all_edges(self, vs=None): \u0026#34;\u0026#34;\u0026#34; 从一个无边的图开始，通过在各个顶点间添加边来生成一个完全图 输入为目标顶点的列表，如果为None,则对所有的点进行全联结 \u0026#34;\u0026#34;\u0026#34; if vs is None: vs = self.vertices() for v1 in vs: for v2 in vs: if v1 is v2: continue # 假设不存在单顶点连通 self.add_edge(Edge(v1, v2)) def bfs(self): \u0026#34;\u0026#34;\u0026#34; 广度优先搜索 \u0026#34;\u0026#34;\u0026#34; # parents 记录所有可达节点与对应的父节点，这里是一个字典，我们将其 可达节点 作为 key，而将其 父节点 作为 value # query_queue 是用来存放待探索节点的 to-do 列表，这里是一个 FIFO node = self.vertices()[0] parents, query_queue = {node: None}, deque([node]) while query_queue: # 总是从 FIFO 的左侧弹出待探索的节点 q_node = query_queue.popleft() for neighbor in self.out_vertices(q_node): if neighbor in parents: continue # 记录探索到的邻居节点及其父节点 parents[neighbor] = q_node # 将其邻居节点推入 to-do 列表 query_queue.append(neighbor) #如果想只得到点的话 可以 # return prints.key() return parents def out_vertices(self, v): \u0026#34;\u0026#34;\u0026#34; 接受一个Vertex并返回邻近顶点（通过一条边连接到给定节点的节点）的列表 \u0026#34;\u0026#34;\u0026#34; return self[v].keys() def out_edges(self, v): \u0026#34;\u0026#34;\u0026#34; 接受一个Vertex并返回连接到给定节点的边的列表 \u0026#34;\u0026#34;\u0026#34; return self[v].values() socket thread／process 文字部分详见小明明 线程篇 和进程篇\nthreading 当前代码版本\u0026mdash;\u0026ndash;》这里\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 #!/usr/bin/env python # -*- coding: utf-8 -*- # Created by vici on 22/01/2017 import threading import platform import time import logging from Queue import Queue from random import randint __doc__ = \u0026#34;\u0026#34;\u0026#34; 抄董伟明,官方文档，廖雪峰 bogo 。。。。 threading 实验结果记录 \u0026#34;\u0026#34;\u0026#34; logging.basicConfig(level=logging.DEBUG, format=\u0026#39;(%(threadName)-9s) |||| %(message)s\u0026#39;,) def timeit(func): \u0026#34;\u0026#34;\u0026#34;一个简单的函数时间装饰器\u0026#34;\u0026#34;\u0026#34; def wrapper(*args, **kwargs): import time start = time.time() func(*args, **kwargs) end = time.time() print(\u0026#39;{} COST: {}\u0026#39;.format(func.__name__, end-start)) return wrapper def show_thread_itself(arg): print(\u0026#34;threading {} is running! \u0026#34;.format(threading.current_thread().getName())) for i in xrange(5): print(\u0026#39;Thread {} \u0026gt;\u0026gt;\u0026gt; {}\u0026#39;.format(threading.current_thread().getName(), i)) time.sleep(1) print(\u0026#34;Thread {} end\u0026#34;.format(threading.current_thread().getName())) pass def fib(n): if n \u0026lt;= 2: return 1 return fib(n-1) + fib(n-2) @timeit def nothread(): fib(34) fib(34) @timeit def withthread(): for i in xrange(2): t = threading.Thread(target=fib, args=(34,)) t.start() main_thread = threading.current_thread() for t in threading.enumerate(): if t is main_thread: continue t.join() balance = 1000 lock = threading.Lock() def change_balance(): global balance balance += 1000 balance -= 1000 def money_laundering(num): for i in xrange(num): change_balance() def money_laundering_priveate(num): for i in xrange(num): lock.acquire() try: change_balance() finally: lock.release() def lock_is_important(): \u0026#34;\u0026#34;\u0026#34; 这里的lock是一种互斥的 可重获的 锁 在一个加锁thread进行完之后将会释放。 lock 相当于信号量（Sempahore） 为 1 \u0026#34;\u0026#34;\u0026#34; @timeit def test1(): print(\u0026#39;Before i go to bank ,I have {}\u0026#39;.format(balance)) t1 = threading.Thread(target=money_laundering, args=(2000000,)) t2 = threading.Thread(target=money_laundering, args=(4000000,)) t1.start() t2.start() t1.join() t2.join() print(\u0026#34;after two public_money_laundering, I have {}\u0026#34;.format(balance)) @timeit def test2(): global balance balance = 2000 print(\u0026#39;Before i go to a new bank ,I have {}\u0026#39;.format(balance)) t3 = threading.Thread(target=money_laundering_priveate, args=(3000000,)) t4 = threading.Thread(target=money_laundering_priveate, args=(3000000,)) t3.start() t4.start() t3.join() t4.join() print(\u0026#34;after two private money_launderingm I have {}\u0026#34;.format(balance)) test1() test2() def consumer_producer(): condition = threading.Condition() def consumer(cond): t = threading.current_thread() print(\u0026#39;{} start , and waiting for proc\u0026#39;.format(t.name)) with cond: cond.wait() print(\u0026#39;{} making resource avaiable to consumer\u0026#39;.format(t.name)) def producer(cond): t = threading.current_thread() with cond: print(\u0026#39;{} producer acaiable !\u0026#39;.format(t.name)) cond.notifyAll() # 激活条件 c1 = threading.Thread(name=\u0026#39;cons1\u0026#39;, target=consumer, args=(condition,)) c2 = threading.Thread(name=\u0026#39;cons2\u0026#39;, target=consumer, args=(condition,)) p = threading.Thread(name=\u0026#39;prod\u0026#39;, target=producer, args=(condition,)) c1.start() time.sleep(1) c2.start() time.sleep(1) p.start() def consumber_producer_event(): \u0026#34;\u0026#34;\u0026#34;一个线程发送事件，其他的线程等待事件的触发 生产者消费者模型\u0026#34;\u0026#34;\u0026#34; from random import randint TIMEOUT = 2 eve = threading.Event() ll = [] threads = [] def consumer(event, l): \u0026#34;\u0026#34;\u0026#34;消费者\u0026#34;\u0026#34;\u0026#34; mt = threading.currentThread() while 1: event_is_set = event.wait(TIMEOUT) if event_is_set: try: integer = l.pop() print(\u0026#39;{} pop from list by {}\u0026#39;.format(integer, mt.name)) event.clear() # 重制事件状态 except IndexError: pass # 刚启动时容错。 def producer(event, l): mt = threading.currentThread() while 1: integer = randint(10, 100) l.append(integer) print(\u0026#39;{} is append to list by {}\u0026#39;.format(integer, mt.name)) event.set() time.sleep(1) pass for name in (\u0026#39;consumer1\u0026#39;, \u0026#39;consumer2\u0026#39;): t = threading.Thread(name=name, target=consumer, args=(eve, ll)) t.start() threads.append(t) p = threading.Thread(name=\u0026#39;producer\u0026#39;, target=producer, args=(eve, ll)) p.start() threads.append(p) for t in threads: t.join() pass def consumer_producer_queue(): \u0026#34;\u0026#34;\u0026#34; 有两种模式 priority 优先级模式 LIFOqueue后进先出模式。\u0026#34;\u0026#34;\u0026#34; # priority 模式 from random import random from Queue import PriorityQueue, LifoQueue q = PriorityQueue() def double(num): return num * 2 def producer(): while 1: wt = random() time.sleep(1) print(\u0026#39;put\u0026#39;, wt) q.put((double, wt)) def consumer(): while 1: task, arg = q.get() print arg, task(arg) q.task_done() for target in (producer, consumer): t = threading.Thread(target=target) t.start() def consumer_producer_priqueue(): \u0026#34;\u0026#34;\u0026#34;priority 优先级队列\u0026#34;\u0026#34;\u0026#34; from random import randint from Queue import PriorityQueue pri_q = PriorityQueue() def triple(n): return n * 3 def consumer(): while 1: if pri_q.empty(): break pri, target, arg = pri_q.get() print(\u0026#39;[PRI: {}], {} * 3 = {}\u0026#39;.format(pri, arg, target(arg))) pri_q.task_done() time.sleep(1) pass def producer(): count = 0 while 1: if count \u0026gt; 50: break pri = randint(10, 100) print(\u0026#39;put priority {} \u0026#39;.format(pri)) pri_q.put((pri, triple, pri)) count += 1 pass for targ in (producer, consumer): t = threading.Thread(target=targ) t.start() time.sleep(1) def daemon_and_not_daemon(): def nd(): logging.debug(\u0026#34;start!\u0026#34;) time.sleep(6) logging.debug(\u0026#34;end!\u0026#34;) def d(): logging.debug(\u0026#34;start\u0026#34;) time.sleep(3) logging.debug(\u0026#34;end\u0026#34;) t = threading.Thread(target=d, name=\u0026#34;deamon\u0026#34;) nt = threading.Thread(target=nd, name=\u0026#39;no-deamon\u0026#39;) t.setDaemon(True) t.start() nt.start() # 论join 的重要性。 t.join() # threading pool \u0026amp;\u0026amp; threading module programing def quadra(strings): return str(strings) * 4 class Worker(threading.Thread): def __init__(self, queue): super(Worker, self).__init__() self._q = queue self.daemon = True self.start() def run(self): while 1: f, args, kwargs = self._q.get() try: print(\u0026#39;USE {} \u0026#39;.format(self.name)) print(f(*args, **kwargs)) except Exception as e: print e self._q.task_done() pass class ThreadingPool(object): def __init__(self, num_con=5): self._q = Queue(num_con) for _ in xrange(num_con): Worker(self._q) def add_task(self, f, *args, **kwargs): self._q.put((f, args, kwargs)) def wait_complete(self): self._q.join() pass def test_threading_pool(): pool = ThreadingPool(10) for _ in xrange(1000): wt = randint(1, 9) pool.add_task(quadra, wt) time.sleep(1) pool.wait_complete() def main(): # nothread() # withthread(） # ----------------- no threading vs use treading------------------------- # show_thread_itself(\u0026#39;no muti\u0026#39;) # print(\u0026#39;threading is running! thraead name is {}\u0026#39;.format(threading.current_thread().getName())) # t = threading.Thread(target=show_thread_itself, args=(123,), name=\u0026#39;Do yourself\u0026#39;) # t.start() # t.join() # print(\u0026#39;threading {} end.\u0026#39;.format(threading.current_thread().getName())) # ------------------ problem on thread lock --------------------------- # lock_is_important() # ------------------ cunsumer / producter model with condition ----------------------- # consumer_producer() # ------------------ cumsumer/ producter model with event ----------------- # consumber_producer_event() # -------- deamon and not deamon threading ------------------------ # daemon_and_not_daemon() # ------------------ cunsumer / producter model with Queue ----------------------- # consumer_producer_queue() # 普通队列 # consumer_producer_priqueue() # 优先级队列 # ------------------ threadingpool ------------ test_threading_pool() pass if __name__ == \u0026#39;__main__\u0026#39;: print(\u0026#34;python version is {}\u0026#34;.format(platform.python_version())) main() print(\u0026#34;done!\u0026#34;) multiprocessing 进程部分 mapreduce with multiprocess 文章搬运, 代码拷贝\n","date":"2017-01-17T15:17:27Z","permalink":"http://blog.heyuhua.com/p/python%E9%87%8D%E4%BF%AE%E4%B9%8B%E6%97%85%E4%B8%80/","title":"python重修之旅（一）"},{"content":"我的·贤者时间·发生在开完周会或者面试结束的时候。。。\n这几天的周会 team 门户 数据统计 页面 kda kpi 算法。 一些必须要做的 结构性的查看python文档,及 python3 的内容。python3.4,5,6的新特性(实在是找工作的时候被问傻了，以前的东西都忘了。） 尽可能多的熟悉kvm libvert open／cloudstack 。（毕竟靠这玩意吃饭。） 每周看一两道算法题。（google可能以后会用的到本宝宝） 熟悉shell 脚本，自动化， docker 源码等（devops部分） 熟悉更多的后端架构： django trnado redis 多看书，多总结，每周最少一篇博客。 一些细节性的东西 （时刻更新） 在过年前需要 重看thread process 。 socket 做总结。 工作 云的虚拟化后台， kvm cloudstack kvm 可行性评估 shell 自动化。 了解一下网络安全的东东 个人额外学习及目标 作为一个全站工程师。什么都要会。 系统的学习前端js，了解 vue，react等前端架构。（前端可视化） 后端补习 sqlchemy 掌握 异步 协程 （python） 了解 ios 应用落地。 了解shell degital 一些细节性的东西 （时刻更新） 具体事项 开始时间 结束时间 [] 在过年前需要 重看thread \u0026amp; process \u0026amp; socket ，做总结 2017.1.16 [] 评估 postgresql + docker （PL／proxy） \u0026amp; prstgres-XC 性能优化方案 2017.1.22 ","date":"2017-01-16T18:23:50Z","permalink":"http://blog.heyuhua.com/p/2017-2018%E5%B9%B4-%E4%B8%A4%E5%B9%B4%E8%AE%A1%E5%88%92/","title":"2017-2018年 两年计划"},{"content":"开平衡车的人都会走残疾人通道。| 做人要谦逊。\n从学校考完试回来，掐指一算已经有一个月没写过代码了。今天下午见到某工程师，相比之下感觉现在的自己是个sb。\n正题：在mac上配置远程开发环境 \u0026gt; 事出有因，在公司工程机上的开发环境是ubuntu16.04，现在要统统挪到本宝宝的mac上。 远程桌面环境。 连windows 直接安装应用windows remote desktop beta, 超级好用。beta版支持分屏，文件拖拽。\n连ubuntu16.04 全色域 unity桌面环境 2k分辨率。\n注意事项：\n目前只在ubuntu16.04 LTS 版本测试过，服务器版本或其他开发版版本暂无解决方案。 此方法要求网络环境及其良好，如内网环境中； 要求工程机性能达到一定程度，否则会卡顿； 大部分内容搬运自 这里 1. 安装tigervnc 下面是大佬写好的install.sh 文件内容。 创建好文件后 直接 chmod +x install.sh \u0026amp; ./install.sh\n或者你也可以逐条复制粘贴。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/bin/sh # 更新 repository sudo apt update -y # install git and devscript. sudo apt install -y git devscript # Remove vnc4server.（或者其它同类vncserver，一定要删除！！！） sudo apt remove -y vnc4server # Create working directory. mkdir tigervnc cd tigervnc # Download source code. git clone https://github.com/TigerVNC/tigervnc cd tigervnc/ # Avoid compiler error.（记得切换版本。胆子大的可以试试不切换，） git checkout ff872614b507d0aa8bfbd09ef41550390cfe658a # Prepare to build package. ln -s contrib/packages/deb/ubuntu-xenial/debian chmod a+x debian/rules sudo apt install -y -o \u0026#39;apt::install-recommends=true\u0026#39; \\ `dpkg-checkbuilddeps 2\u0026gt;\u0026amp;1 | \\ sed -e \u0026#39;s/.*build dependencies://g\u0026#39; -e \u0026#39;s/([^)]*)//g\u0026#39;` # Build package. (大概一杯咖啡的时间) fakeroot debian/rules binary cd .. # Install package with resolving dependent package. sudo dpkg -i *.deb || (sudo apt-get -f install -y ; sudo dpkg -i *.deb || exit 1) cd .. 2. 创建 ~/.xession 文件 文件内容：\n1 2 3 4 5 6 7 8 9 10 11 12 /usr/lib/gnome-session/gnome-session-binary --session=ubuntu \u0026amp; /usr/lib/x86_64-linux-gnu/unity/unity-panel-service \u0026amp; /usr/lib/unity-settings-daemon/unity-settings-daemon \u0026amp; for indicator in /usr/lib/x86_64-linux-gnu/indicator-*; do basename=`basename ${indicator}` dirname=`dirname ${indicator}` service=${dirname}/${basename}/${basename}-service ${service} \u0026amp; done unity 3. 添加 gnome-control-center 如果显示文件已存在， 就可以跳过了。（比如说之前做过个性化设置什么的）\n1 $ sudo ln -s /usr/bin/unity-control-center /usr/bin/gnome-control-center 4. 运行vncserver 创建vnc密码：\n1 2 3 4 $ vncpasswd Password: Verify: Would you like to enter a view-only password (y/n)? n 运行vncserver，端口号为 5900 + 序号， 下面的端口就是： 5900 + 1 = 5901 同时还指定了分辨率为1920*1080\n1 2 3 4 5 6 $ vncserver -geimetry 1920x1080 New \u0026#39;ubuntu-16:1 (hiroom2)\u0026#39; desktop is ubuntu-16:1 Starting applications specified in /home/hiroom2/.vnc/xstartup Log file is /home/hiroom2/.vnc/ubuntu-16:1.log 你也可以在~/vnc/startup 里设置分辨率。\n5. mac连接　在 mac桌面环境下 使用快捷键⌘（command）+ k 呼出连接器 输入 你的vnc服务器 vnc://ip:port 连接\n使用pycharm做远程开发 配置方面借鉴了 \u0026ndash;\u0026gt; 那年八月的博客\n杂项 使用 GNU commandTool替换默认版本 注意到这个事情是因为 默认的 grep 太诡异。教程-\u0026gt; 传送门\n代理的配置（不得不说的是今天 看到百度首页的title 居然是 我爱你中国 ） 如果使用shadowshocks， 最好把端口改成1080 而不是默认的1086（因为之前做了一些配置文件云同步东东） proxifier 负责全局调度（google_photo_backup \u0026amp; bropbox \u0026amp; 不支持socks5的可以很轻松的搞定） github 什么的需要额外配置 git config --global http.proxy .... 漏网之鱼用proxychains4 ","date":"2017-01-01T00:00:00Z","permalink":"http://blog.heyuhua.com/p/mac%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%80%E4%BA%9B%E9%85%8D%E7%BD%AE/","title":"mac开发环境的一些配置"},{"content":"{{ highlight }} 推荐使用cvim，本人不再使用 vimium \u0026ndash; 2017.10.03 {{ /highlight }}\nCTO大人把组内gitlib的地址route到了ooxx.com，受他的启发我把*.zhihu.com host 到了冷宫，跟百度作伴。\n写在周末的话 逃离帝都，工作离家太近了。一点都不自由。 以前一直不把清华的人当回事，因为我身边的水木硕士毕业生也不过是中人之姿。 今晚在github 上闲逛才发现他妈的有些变态真的是很变态啊。 99%的屁民统治者地球，1% 的大屌改变了世界。（改编自姚期智的名言） vimium 小炒 被某一直用firefox vim插件的同事洗脑, vimium 其实还有很多不足。但是谁让我用chrome呢 今天被google强行打广告也没什么办法 可能会用到的： 快捷键 作用 gs 查看网页源码 i 关闭vim 功能。直到ESC r 刷新页面 gu 返回网页的上层目录 gU 返回网页的顶层目录（host） yy 复制当前网页链接 yf 开启选择模式，选择复制页面内的链接 gi 定位到页面第一个文本框，搜索引擎绝配。 alt + f 以新标签页的形式打开多个链接 ]], [[ 上一页下一页，测试了几个页面，sphinx 类的文档页支持,baidu支持，但是google不支持 m 添加标签， 如 ma 给当前页面浏览状态添加标签a, mA 给当前额页面的浏览状态添加全局标签 tab上面那个点 如果当前tab 有局部标签a , 键盘tab上面的那个点 + a 可以到a标签标记的位置， +A 可以跳转到全局标签A gE 编辑当前页面url新页面打开 g0 到第一个tab g$ 最后一个 g + 数字 跳转到顺位第n个tab T 在 当前打开的tab中搜索并跳转（我还是习惯用这个） yt 复制当前tab w 将当前tab移动到新窗口 \u0026gt;\u0026gt; \u0026lt;\u0026lt; 把当前tab 向左挪，向右挪 gi 命令用起来没有想象中的好用，需要配合gg\n","date":"2016-12-18T20:55:14Z","permalink":"http://blog.heyuhua.com/p/vimium%E8%BF%9B%E9%98%B6%E5%B0%8F%E7%82%92/","title":"vimium进阶小炒"},{"content":"生死怎能看淡, 不服就是要干\n一. 亲身经历 python 是我第一个拿出10分认真的态度去学习的语言.\n但是可能需要12分的认真。因为周围毕竟还有一些十分认真的人在尝试着用她解决问题。之前零零散散的坑笔记也懒得往过搬了。\npython2： 对 range 的想法 于 2016年12月15日16:26:12 一个小时前CTO大人（以下简称杰哥）过来找我说一个很奇怪的问题：同一个脚本检索两台数据库，一台国内一台国外，国外的没出问题，国内的时不时报错。 （讲道理我的第一反应是\u0026hellip;觉得国外的服务器香一些。。。）\n登到监控服务器 vi+ pdb 一顿调试，问题出在了神奇的地方：\n1 2 3 4 5 6 7 8 # python伪代码 with open(\u0026#39;file/to/path\u0026#39;, \u0026#39;r\u0026#39;) as f: localfsize = getsize(f) for i in range(1, localfsize, 1): f.seek(size-i) # dosomething.., pass 第一次运行 for i in range 就报出memeryError，很自然的想到是range.\n因为python2 的range 返回的还是一个完整的数组， 而推荐使用的xrange 返回的是一个生成器，占用内存空间更小.\n一开始我是拒绝的，因为之前一直都是懒的多写那个x,因为本屁民觉得在2016年的今天，一个多占了几mb内存的range并不可能发生内存溢出错误\n像我们这种土豪公司，开发机都是4核8线程 64g内存，怎么可能运行个脚本会发生内存错误？\n它真的发生了：\n这个故事发生在一个十分尴尬的环境，杰哥把脚本跑在了他自己的开车服务器（aws大流量1g内存1核）， 整个脚本的流程是开两个线程，分别从国内集群和国外集群的log_db上查询 \u0026raquo; 增量追加到内部处理log。\n一个本地日志文件大概是300mb-1g不等的样子。 没错，日志很大，,但又恰好都没有到造成内存溢出的程度，所以就愉快的继续运行了，到了range 这里，localfilesize刚好是一个千万级别的整形数字（假设为1kw），即使是按c的计算方法，不考虑堆栈大小，在内存重要占用空间为：\n1 2 # 顺便说一句python 3.6 新功能:写长数字时可以在中间加下划线`_` ,方便阅读 4 × 1000_0000 = 4000_0000B = 40000KB = 40MB 同事脑补了触发memoryERROR 两种可能:1. 这个大数组挤爆了栈空间 | 2. 它成了挤爆内存的最后一根稻草\n于 2016年12月15日20:54:08 上面的脑补不是很靠谱，刚才又做了一堆测试，发现了更多的问题。\n测试过程\n偷了台实验室的计算服务器 :D 1 2 3 # 测试range 占用内存函数 from sys import getsizeof foo1 = lambda x:getsizeof(range(int(10**x))) 1 2 # 返回的数字与实际最高内存占用出入很大, 另开一个shell 监控memory watch -n 0.01 \u0026#34;free -m\u0026#34; foo1(x) 结果：\nx的值 运行时最高占用 10 \u0026lsquo;memoryError\u0026rsquo; 9 31138_mb 8 3111_mb 7 77mb 跟之前口算的理想大小40mb 没差, 可以接受\n然后给foo1 做一些修改：\n1 2 from sys import getsizeof foo2 = lambda x:getsizeof(range(0, int(10**x), 1)) foo2(x) 结果：\nx的值 运行时最高占用 10 \u0026lsquo;memoryError\u0026rsquo; 9 31138_mb 8 3111_mb 7 235mb **比较两次 foo(7) 可怕的事情发生了， range 生成同一内容的两种调用方法会有两种内存占用。 **\n至于国外集群不出问题的原因， 国外服务器一天生产的log 比较少，所以文件也比较小。so \u0026hellip;\nend.\n为什么我的super报错？ 于 2016年12月16日15:06:31 问题代码： 1 2 3 4 5 6 7 8 9 10 class A: def __init__(self): pass class B(a): def __init__(self): super(B, self).__init__() c = B() 上述代码会报TypeError: super() argument 1 must be type, not classobj错误\n解决办法 class A: 旧的类型写法已经被弃用， 改用class A(object) 万事大吉\n刚才我在想，为什么我不会范这个错误? 因为我已经懒到了根本不会写class\u0026hellip; 这就是我的BOP 编程思想： Bed Oriented Programming 二. 搬运wtfpyhon项目 + 自评 项目地址： wtfpy 该项目使用DO WHAT THE FUCK YOU WANT 开源协议。所以应该在不获取授权的情况下搬运应该是没什么事的。\npython 2的wft尽量少写。\n字符编码 1 2 In [2]: \u0026#39;value\u0026#39; == \u0026#39;valuе\u0026#39; Out[2]: False 坑比指数 ⭐️\n虽然看起来很魔幻，但是现实生活中能打出两个e的几率其实感觉相当低。必经我特么连cyrillic 码是啥都不知道。。。\n缩进 | py-version \u0026lt; 3 1 2 3 4 5 6 7 8 def square(x): \u0026#34;\u0026#34;\u0026#34; A simple function to calculate square of a number by addition. \u0026#34;\u0026#34;\u0026#34; sum_so_far = 0 for counter in range(x): sum_so_far = sum_so_far + x return sum_so_far 上面的代码会输出 10而不会输出想象的 100\n坑比指数⭐️\n这码在idea里甚至会报错。。。就算vim党一般在配置里也会显式区分tab与spcace的区别（1tab=4space or 2space）\n原因：在python2 的解释器中，1tab = 8space，所以return语句进入了for循环。python3已修复。\npython的hash特性 坑比指数⭐️⭐️\neg：\n1 2 3 4 some_dict = {} some_dict[5.5] = \u0026#34;Ruby\u0026#34; some_dict[5.0] = \u0026#34;JavaScript\u0026#34; some_dict[5] = \u0026#34;Python\u0026#34; magic:\n1 some_dict[5.0] == some_dict[5] == \u0026#34;python\u0026#34; \u0026ldquo;javascript\u0026quot;终究会被python无情碾压 ;D\npython的 list 使用 下标的hash作为实际索引，同时使用hash的还有equal。\n如果你希望 5.0 == 5 这个判断句在python中是成立的，就需要接受 hash(5.0) == hash(5)。\n同时也应该能接受 javascript被python碾压的结果。\n生成器 for x in y if z 坑比指数⭐️⭐🌟\neg:\n1 2 3 array = [1, 8, 15] g = (x for x in array if array.count(x) \u0026gt; 0) array = [2, 8, 22] Output:\n1 2 In [3]: print(list(g)) In [4]: 8 在generator语法中， in 后面的对象是在声明时被确定的，而 if 后面的语句则会在生成器被执行时才被确定。所以point(list(g))等价于：\n1 print([x for x in [1, 8, 15] if [2, 8, 22].count(x) \u0026gt; 0]) dict迭代中编辑 坑比指数：⭐️🌟\n就在看wftpython 前一天，还收到一个想学python的前端同事抱怨：\n1 2 3 4 # 为什么下面的语句会报错？！ a = {\u0026#39;a\u0026#39;:1, \u0026#39;b\u0026#39;=2} for i in a.keys(): a.pop(i) 哈哈哈哈这事就这么过去吧。（这个锅python是不能背的）\nwtfpy中的eg：\n1 2 3 4 5 6 x = {0: None} for i in x: del x[i] x[i+1] = None print(i) output:\n1 2 3 4 5 6 7 8 0 1 2 3 4 5 6 7 tips：永远不曾要尝试在iter dict时尝试添加和修改key.\nList的迭代中编辑 坑比指数⭐️🌟\neg:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 list_1 = [1, 2, 3, 4] list_2 = [1, 2, 3, 4] list_3 = [1, 2, 3, 4] list_4 = [1, 2, 3, 4] for idx, item in enumerate(list_1): del item for idx, item in enumerate(list_2): list_2.remove(item) for idx, item in enumerate(list_3[:]): list_3.remove(item) for idx, item in enumerate(list_4): list_4.pop(idx) output:\n1 2 3 4 5 6 7 8 \u0026gt;\u0026gt;\u0026gt; list_1 [1, 2, 3, 4] \u0026gt;\u0026gt;\u0026gt; list_2 [2, 4] \u0026gt;\u0026gt;\u0026gt; list_3 [] \u0026gt;\u0026gt;\u0026gt; list_4 [2, 4] 逐个分析：\n​\tlist_1 的 enumrate的迭代中, del item 只是删除了 list中对象的副本。所以并不会变。\n​\tlist_2和list_4在遍历的第一步删除数字1后list的内容变成了[2, 3, 4] .这些剩余的元素下标会顺延，比如 2的下标会变成0， 3的变成1，所以，当第二次遍历时，index 为 1的元素3将会被删除。\n字符串联结 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def add_string_with_plus(iters): s = \u0026#34;\u0026#34; for i in range(iters): s += \u0026#34;xyz\u0026#34; assert len(s) == 3*iters def add_string_with_format(iters): fs = \u0026#34;{}\u0026#34;*iters s = fs.format(*([\u0026#34;xyz\u0026#34;]*iters)) assert len(s) == 3*iters def add_string_with_join(iters): l = [] for i in range(iters): l.append(\u0026#34;xyz\u0026#34;) s = \u0026#34;\u0026#34;.join(l) assert len(s) == 3*iters def convert_list_to_string(l, iters): s = \u0026#34;\u0026#34;.join(l) assert len(s) == 3*iters 1 2 3 4 5 6 7 8 9 \u0026gt;\u0026gt;\u0026gt; timeit(add_string_with_plus(10000)) 100 loops, best of 3: 9.73 ms per loop \u0026gt;\u0026gt;\u0026gt; timeit(add_string_with_format(10000)) 100 loops, best of 3: 5.47 ms per loop \u0026gt;\u0026gt;\u0026gt; timeit(add_string_with_join(10000)) 100 loops, best of 3: 10.1 ms per loop \u0026gt;\u0026gt;\u0026gt; l = [\u0026#34;xyz\u0026#34;]*10000 \u0026gt;\u0026gt;\u0026gt; timeit(convert_list_to_string(l, 10000)) 10000 loops, best of 3: 75.3 µs per loop 耗时天壤之别。但是坑比等级：⭐️\n大三找实习的时候就有hr叔叔问过我你喜欢用什么做字符串联结。本萌新立马说 用➕。然后那个面试没过。加号的慢是因为 python中的str为不可变对象。加法作为一个双目运算符，每次做一次字符串联结都要创建一次新str对象。当对多个string进行联结时，比如 ‘’aa‘’ +\u0026lsquo;\u0026lsquo;bb\u0026rsquo;\u0026rsquo;+\u0026ldquo;cc\u0026rdquo;, 会首先生成中间变量 ”aabb“,在由“aabb”+\u0026ldquo;cc\u0026rdquo; 得到随后的 “aabbcc”\npython内置的字符串填充工具 .format 和 %在做长字符串处理时效率很高, 但是在处理短字符串时表现欠佳。\n使用join是最好的选择，一次join只会创建一次对象，多目运算神清气爽。\n再给join创建 字符串数组的时候 不要使用append，list的动态扩容内存开销极大。\n​\n字符串滞留 1 2 3 4 5 6 7 8 9 10 11 \u0026gt;\u0026gt;\u0026gt; a = \u0026#34;some_string\u0026#34; \u0026gt;\u0026gt;\u0026gt; id(a) 140420665652016 \u0026gt;\u0026gt;\u0026gt; id(\u0026#34;some\u0026#34; + \u0026#34;_\u0026#34; + \u0026#34;string\u0026#34;) # Notice that both the ids are same. 140420665652016 # using \u0026#34;+\u0026#34;, three strings: \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026#34;s1 = s1 + s2 + s3\u0026#34;, setup=\u0026#34;s1 = \u0026#39; \u0026#39; * 100000; s2 = \u0026#39; \u0026#39; * 100000; s3 = \u0026#39; \u0026#39; * 100000\u0026#34;, number=100) 0.25748300552368164 # using \u0026#34;+=\u0026#34;, three strings: \u0026gt;\u0026gt;\u0026gt; timeit.timeit(\u0026#34;s1 += s2 + s3\u0026#34;, setup=\u0026#34;s1 = \u0026#39; \u0026#39; * 100000; s2 = \u0026#39; \u0026#39; * 100000; s3 = \u0026#39; \u0026#39; * 100000\u0026#34;, number=100) 0.012188911437988281 坑比等级：⭐️\n同样是没什么卵用的字符串机制。在进行多次重复三字符串联结时，使用 += 要比单纯的两个加号快很多。因为在使用+=时 等号右面的s2+s3对象并不会销毁。\nelse的扭曲之处 1 2 3 4 5 6 7 def does_exists_num(l, to_find): for num in l: if num == to_find: print(\u0026#34;Exists!\u0026#34;) break else: print(\u0026#34;Does not exist\u0026#34;) 1 2 3 4 5 \u0026gt;\u0026gt;\u0026gt; some_list = [1, 2, 3, 4, 5] \u0026gt;\u0026gt;\u0026gt; does_exists_num(some_list, 4) Exists! \u0026gt;\u0026gt;\u0026gt; does_exists_num(some_list, -1) Does not exist for-else会在for循环内无break发生后触发else.\n同理 try-except-else 无脑三连在try中语句正确执行后才会触发else.\n坑壁指数：⭐️\n是是非非——is 1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt;\u0026gt;\u0026gt; a = 256 \u0026gt;\u0026gt;\u0026gt; b = 256 \u0026gt;\u0026gt;\u0026gt; a is b True \u0026gt;\u0026gt;\u0026gt; a = 257 \u0026gt;\u0026gt;\u0026gt; b = 257 \u0026gt;\u0026gt;\u0026gt; a is b False \u0026gt;\u0026gt;\u0026gt; a = 257; b = 257 \u0026gt;\u0026gt;\u0026gt; a is b True 坑比指数：⭐️⭐️⭐️⭐️\nis 与 == 的区别在于, 前者比较的是操作数是否为同一对象，即检查操作数id， 后者考量的是对象的数值是否相等，比如说使用 hash。\n这里的现象涉及到了python的实现，当python启动时，整型数字中 -5 到 256的所有数字都会以对象形式预分配到内存中。所以 当 a，b为256 时， 他们都是一个256对象的引用, a is b返回True。\n而当创建一个 大于256的数字时，则会生成一个新的integer对象。那么第二段case返回False也就理所应当了。\n最后的True则涉及到另一个python的实现。当在一行初始化赋值多个变量时，同一值只会被创建一次。a = 257; b = 257, c, d= 257, 257 这里 a is b,c is d 都会被判True。\n循环内的闭包 1 2 3 4 5 6 7 8 9 funcs = [] results = [] for x in range(7): def some_func(): return x funcs.append(some_func) results.append(some_func()) funcs_results = [func() for func in funcs] 1 2 3 4 \u0026gt;\u0026gt;\u0026gt; results [0, 1, 2, 3, 4, 5, 6] \u0026gt;\u0026gt;\u0026gt; funcs_results [6, 6, 6, 6, 6, 6, 6] 坑比指数：⭐️⭐️✨\n定义在循环中的闭包 如果使用外部循环变量，闭包将会绑定该变量而不是变量值。所以在循环结束后调用闭包时，闭包内使用的循环变量是其遍历结束时的值。\n1 2 3 4 5 funcs = [] for x in range(7): def some_func(x=x): return x funcs.append(some_func) 这种局部函数的写法更加妥当。\n##被调戏的自加## input:\n1 2 3 a = [1, 2, 3, 4] b = a a = a + [5, 6, 7, 8] Output:\n1 2 3 4 \u0026gt;\u0026gt;\u0026gt; a [1, 2, 3, 4, 5, 6, 7, 8] \u0026gt;\u0026gt;\u0026gt; b [1, 2, 3, 4] 嗯，似乎是正常的。下面是核爆现场。\nInput：\n1 2 3 a = [1, 2, 3, 4] b = a a += [5, 6, 7, 8] Output:\n1 2 3 4 \u0026gt;\u0026gt;\u0026gt; a [1, 2, 3, 4, 5, 6, 7, 8] \u0026gt;\u0026gt;\u0026gt; b [1, 2, 3, 4, 5, 6, 7, 8] 坑比指数 ⭐️⭐️⭐️✨\na = a + [5, 6, 7, 8] 会生成一个新list赋值给a, 此时的b就成了旧的a对象的唯一引用。\na += [5, 6, 7, 8] 会产生不同的结果是因为这里list的自加实现 使用了extend 直接在原list上添加新对象。 所以 这里a和b此时还是指向的同一个list。\n不可变对象被玩弄### 同样是利用了上一条 list 的 自加实现。\n1 2 3 4 5 \u0026gt;\u0026gt;\u0026gt; another_tuple = ([1, 2], [3, 4], [5, 6]) \u0026gt;\u0026gt;\u0026gt; another_tuple[2] += [99, 999] TypeError: \u0026#39;tuple\u0026#39; object does not support item assignment \u0026gt;\u0026gt;\u0026gt; another_tuple ([1, 2], [3, 4], [5, 6, 1000, 99, 999]) 坑比指数：⭐️⭐️⭐️⭐️\n这个是连环坑。首先这个自加会被执行并赋值，同时还会报tuple不可变的错误。\n我觉得这就是个大bug。。。\n消失的外部变量### 1 2 3 4 5 e = 7 try: raise Exception() except Exception as e: pass 1 2 \u0026gt;\u0026gt;\u0026gt; print(e) NameError: name \u0026#39;e\u0026#39; is not defined 坑比指数：⭐️\n虽然很奇葩。但是如果按照规范coding是不会犯这种错误的。\n这个现象涉及到expect as 语法的实现逻辑，当离开except 上下文时，会有一个隐式的del 语句将e删除.\n一个正常的except语句：\n1 2 except E as N: foo 会被解析成酱：\n1 2 3 4 5 except E as N: try: do_any_thing_you_like finally: del N （挑着翻译看心情。插眼 2017.09.05， 第二次更新 2017.09.18）\n","date":"2016-12-15T16:17:05Z","permalink":"http://blog.heyuhua.com/p/python-%E7%9A%84%E5%9D%91/","title":"python 的坑 "},{"content":"linux忽悠原则： 一切皆文件， 通信皆管道， 不管闲事，不说废话.(只能信50%)\n统计常用命令 （使用次数最多的10条命令） 1 history | awk \u0026#39;{print $2}\u0026#39; | sort | uniq -c | sort -k1,1nr | head -10n Tips: ohmyzsh扩大了history 记录行数到2000，大概索引宝宝平时一个月的命令 ，可以按需求修改 ~zshrc\n批量修改文件名（rename） rename 在各发行版语法不同，写通用脚本宁可用 mv \u0026hellip; 示例运行在ubuntu16.04\n修改当前目录下的所有.log 文件为.json 格式 1 rename \u0026#39;s/.log$/.json/\u0026#39; *.log 递归删除匹配到的文件 首先需要知道的是在bash／zsh 环境中， 不加引号的语句会首先被zsh 或者 bash 解析 所以 类似 rm -r *.pyc 这种语句是错误的（并不会像你想象的那样删除所有子目录下的pyc 文件）\nstackoverflow上评分最高的两个答案： find . -name \u0026quot;*.pyc\u0026quot; -exec rm -rf {} \\; find . -name '*.pyc' -delete 这种显然看上去更为安全一些。毕竟看到 rm -rf 这样的东东总是感觉很害怕。 命令行reformat log 文件 比如说将log中的回车显式表示。sed -e ’s/#012/\\n/g’\n","date":"2016-12-02T00:00:00Z","permalink":"http://blog.heyuhua.com/p/linux-shell-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"linux shell 实用技巧"},{"content":" They are gonna get me one wey or another.\n从一个分支上建立新分支 首先要切换到爹爹分支 1 git checkout master 然后生成儿子 1 git checkout -b hedada 然后提交到云 1 git push origin hedada 建立与远程分支的联系 1 git push --set-upstream origin hedada 删除分支 并删除云上的自己 删除本地 1 git branch -d hedada 删除远程分支 1 git push origin 空格:hedada 将分支合并到当前分支 如果是master\n可以使用marge提交其他分支的修改\n1 2 3 git checkout master git marge hedada 如果在hedada 想把 远程的 master 合并倒当前 1 2 3 4 5 6 7 git pull origin master git add . git commit -m \u0026#34;update\u0026#34; git push 将本地缓存的东东删除 1 git reset HEAD 1 2 3 git branch -m old_branch new_branch # Rename branch locally git push origin :old_branch # Delete the old branch git push --set-upstream origin new_branch # Push the new branch, set local branch to track the new remote pull 时候把本地覆盖 1 2 git fetch --all git reset --hard origin/master init仓库并连接到远程 1 2 git init git remote add orgin 我在检查代码的时候发现把种子传上git去了，觉得很羞耻，想让他在记录中消失 我想保存当前代码（修复过的），只是把历史线中的一次提交删除\n1 2 3 4 5 6 7 8 9 10 11 12 # 首先git log 查看 提交历史 得到代有种子的那次提交 git log # 从想要删除的commit的上一次提交开始删除提交历史（很绕口） git rebase -i \u0026lt;想删除的提交的上一个提交\u0026gt; # 把要删除的提交行删掉， vi 环境，保存退出 # 将冲突修改完成后 git rebase --continue #覆盖远程提交历史 git push -f # 在项目repo中进行svn模式的开发。 当与团队同事在一个三方repo中进行合作开发。 比如 有一个repo asm_team/client， 你和同时分别有 luoli/client, dashu/client的fork， 你们要同时在一个主repo的branch ‘feature/next_version’上开发。\n进行开发。 1 2 3 4 5 6 7 8 # 切换到远程开发分支 git checkout asm_team/feature/next_version # 创建本地开发分支 git checkout -b feature/next_version # 一顿操作之后提交 ... git commit -m \u0026#39;v1.2.3\u0026#39; git push asm_team feature/next_version:feature/next_version 同步线上代码 1 git pull --rebase asm_team/feature/next_version submodule 添加子模块到项目 1 git submodule add woailuoli993/ooooxxxx 拉取一个包含子项目的项目。。 1 2 git submodule init git submodule update 让项目中的所有子项目统一行动 1 2 # 比如 列出所有的子项目的diff。 git submodule foreach git diff ","date":"2016-12-01T19:09:25Z","permalink":"http://blog.heyuhua.com/p/git-%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/","title":"git 使用总结"},{"content":"看那白狐脸, 一手绣冬, 一手春雷\n写在之前\nvim 我真的是不是喜欢用。处于同事们的威逼，才稍微学了一点点皮毛。 上古神器尽量少用。\n不定时看心情更新\n批量tab 法1 先按10次 ESC(所以你告诉我新mac怎么办*1) :10,100\u0026gt; 10到100行向右tab 1 次 法2 v 视图模式 选好 shift + \u0026gt; 向右tab一次 升级版法2 v 视图模式 6\u0026gt; 向右6次tab 将当前编辑的行挪到屏幕中央 先按10次 ESC(所以你告诉我新mac怎么办*2) z + . 替换 语法 [addr]s/源字符串/目的字符串/[option] 全局替换命令为：:%s/源字符串/目的字符串/g\n[addr] 表示检索范围，省略时表示当前行。\n如：1，20 ：表示从第1行到20行； % ：表示整个文件，同“1,$”； . ,$ ：从当前行到文件尾； s : 表示替换操作\n[option] : 表示操作类型\n如：g 表示全局替换; c 表示进行确认 p 表示替代结果逐行显示（Ctrl + L恢复屏幕）； 省略option时仅对每行第一个匹配串进行替换； 如果在源字符串和目的字符串中出现特殊字符，需要用”\\”转义\neg： 将 全文中所有的‘@main’ 替换成 ‘@api’ :%s/@main/@api/g\n可以使用正则语法\n","date":"2016-11-30T16:50:53Z","permalink":"http://blog.heyuhua.com/p/vim%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"vim使用技巧"},{"content":"本事借的钱，为什么要还？\n此文章脱胎于我在stackoverflow的某回答\ncelery 高阶用法 需求 项目需要多个任务队列进行任务分发，每个队列的任务都会请求获取某种资源。 CTO大人给的建议是使用线程模型自己维护队列。（说实话我当时就怒了） 什么年代了？昂？当然我并没有为此而辞职\n环境 linux (Centos/ubuntu/arch) pyhon 2.7 celery 任务队列中间件(djcelery 及flask 都适用) 干活 celery worker 部署代码 下面的代码实现了：\n生成了一堆以w_* 命名的 worker 和 以 q_*命名的任务队列，限制各个worker的并发数及绑定worker 与队列 w_celery 负责默认celery队列，并发数为10， 剩下的worker 都为单线程任务， 绑定各自的任务队列 -A celery_worker.celery 表明了任务内容 -Q celery 设置了默认队列为 celery --pidfile,--logfile 定义了进程文件及日志名称规范及存放地点 1 2 3 4 5 6 7 8 9 10 11 celery multi start w_celery w_sas w_aosp w_avpro w_pw764 w_pw786 w_pxp w_cwxp w_cw786 \\ -c 1 -A celery_worker.celery -l debug -Q celery --pidfile=/tmp/celery_%n.pid --logfile=/tmp/celery_%n.log \\ -Q:w_celery celery -c:w_celery 10 \\ -Q:w_sas q_sas \\ -Q:w_aosp q_aosp \\ -Q:w_avpro q_avpro \\ -Q:w_pw764 q_pw764 \\ -Q:w_pw786 q_pw786 \\ -Q:w_pxp q_pxp \\ -Q:w_cwxp q_cwxp \\ -Q:w_cw786 q_cw786 task定义及调用方法示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 定义 @celery.task def sub_sas(*args): # 申请某独占资源 pass # 如何在调用时绑定queue def sub(): sub_sas.apply_async(args=(), queue=\u0026#39;q_sas\u0026#39;) # 将sas任务 提交到q_sas 队列，从而交由w_sas 实现 通过这样的绑定即可实现worker的术业专攻，并通过上下文控制（with）独占资源的锁\n老哥稳！\n","date":"2016-11-29T00:00:00Z","permalink":"http://blog.heyuhua.com/p/celery%E4%BB%BB%E5%8A%A1%E5%88%86%E5%8F%91-%E6%9C%AF%E4%B8%9A%E6%9C%89%E4%B8%93%E6%94%BB%E7%9A%84worker%E4%BB%AC/","title":"celery任务分发-术业有专攻的worker们"},{"content":" 副标题+ 内容缩略：好看的皮囊千篇一律，有趣的人200多斤。想变的有趣还是得多吃多睡。。。\n1 2 3 ChangeLog: 「2017.11.30」 生成框架迁移到 `hugo` 「2017.12.12」 主题迁移到 hugo-tranquilpeak-theme 为什么要开这个博客 之前有在csdn 和cnblog 写过博客，作为一个永远18岁的小正太，它们无法跟我一起保持青春 写了很多工作笔记存在印象，在考虑一点一点把它们公开，而且我很有先见之明的留下了markdown底稿 我想证明一件事：你永远都会觉得“1年前的我是个sb.” 而不是老的时候觉得”我年轻的时候就像个sb.” 副标题为随机Unicode编码组合，由本人随机生成。 ","date":"2016-11-29T00:00:00Z","permalink":"http://blog.heyuhua.com/p/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BC%80%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"为什么要开个人博客"},{"content":" 入门 入门手册一(偏理论) 入门手册二(偏实践) qus1: 使用安装docker后 使用普通用户无法运行docker run AND docker version 错误提示: Cannot connect to the Docker daemon. Is the docker daemon running on this host?\n在使用groupadd 添加了docker 用户组及 将当前 ==$USER== 添加到用户组之后,务必要进行注销重新登录\n1 cat /etc/group # 可以获取当前系统所有组及权限 技巧1: 使用阿里云做ecs 的docker 镜像下载加速 点进这里申请及查看自己的加速地址\n一下是ubuntu 14.04 的配置加速器命令 1 2 echo \u0026#34;DOCKER_OPTS=\\\u0026#34;\\$DOCKER_OPTS --registry-mirror=https://95s2tvj3.mirror.aliyuncs.com\\\u0026#34;\u0026#34; | sudo tee -a /etc/default/docker sudo service docker restart 以下是 centos 7的.. 1 2 3 4 sudo cp -n /lib/systemd/system/docker.service /etc/systemd/system/docker.service sudo sed -i \u0026#34;s|ExecStart=/usr/bin/docker daemon|ExecStart=/usr/bin/docker daemon --registry-mirror=https://95s2tvj3.mirror.aliyuncs.com|g\u0026#34; /etc/systemd/system/docker.service sudo systemctl daemon-reload sudo service docker restart 其中那个神奇的域名(https://95s2tvj3.mirror.aliyuncs.com)是 阿里云开发者账号生成的个人加速镜像地址\n技巧2: 修改docker 容器镜像的默认地址（ubuntu16.04）： 1 2 3 4 5 # 关闭服务 systemctl stop docker sudo mv /var/lib/docker /data/docker sddo ln -s /data/docker /var/lib/docker systemctl start docker docker 部署工具(自动化部署): Swarm Rancher Kubernetes Helios 大白话 ** docker与虚拟机的相互理解:\ndocker 像啥 术语 镜像 iso 系统镜像 image 容器 跑着的虚拟机 Container 仓库 github repository ++使用docker run 命令 相当于 在虚拟机中进行了一次从iso 到 运行实例的 过程++\ndocker client 操纵 docker daemon, docker deamon 为底层的管家 由上面的大白话可以推测出, 镜像(image) 是只读对象 ,类似于工厂函数,可以创建多个实例 容器 因为镜像的只读性, 容器在启动时会在 最上层添加 可写层 做个性化部署 docker 基于 linux 的容器机制实现 其中关于 namespace 的进程 隔离部分 及 文件系统的分层 readonly / readwrite 决定了 docker 的运行机制\n镜像操作 显示所有本地存放的镜像 1 docker images 从镜像仓库拉取镜像 1 docker pull imagename 运行镜像 1 docker run imagename 容器常用操作命令 启动容器 启动容器有两种方式，一种是基于镜像新建一个容器并启动，另外一个是将在终止状态（stopped）的容器 重新启动。\n1 2 $sudo docker run node:latest /bin/echo \u0026#34;Hello World\u0026#34; $sudo docker run -t -i node:latest /bin/bash 其中， -t 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上， -i 则让容器的标 准输入保持打开。 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 docker run 命令参数较多，可以通过以下命令docker run --help查看参数\n可以利用 docker start [containerId|containerName] 命令，直接将一个已经终止的容器启动运行。\n重启容器 docker restart 命令会将一个运行态的容器终止，然后再重新启动它。\n守护态运行 更多的时候，需要让 Docker 容器在后台以守护态（Daemonized）形式运行。此时，可以通过添加 -d 参 数来实现。\n进入容器 docker exec -it [containerId|containerName] /bin/bash 获取容器的输出信息\n要获取容器的输出信息，可以通过 docker logs [containerId|containerName] 命令。\n查看容器 1 2 $ sudo docker ps # 查看正在运行的容器 $ sudo docker ps -a # 查看所有的容器状态 删除容器 可以使用 docker rm 来删除一个处于终止状态的容器。如果要删除一个运行中的容器，可以添加 ==-f== 参数。Docker 会发送 SIGKILL 信号给容器。 删除所有容器 docker rm $(docker ps –a –q)\ndocker run 命令 重要参数 ==-b==: 默认是空，附加在已存在的网桥上，如果是用\u0026rsquo;none\u0026rsquo;参数，就禁用了容器的网络\n==-p==：随机映射容器的所有暴露端口给主机 -p: 映射容器端口给主机 ==\u0026ndash;env==: 设置环境变量 ==-v==: 挂载一个数据卷 ==-entrypoint==: 覆盖镜像的默认的入口指令 ==\u0026ndash;name==: 给容器指定一个名称 ==\u0026ndash;link==: 连接另外的容器\n在原有镜像的基础上创建镜像 首先在docker run 之后一顿操作 然后:\n1 2 docker commit -m \u0026#34;提交说明\u0026#34; -a \u0026#34;指定更新用户信息\u0026#34; 01231412981 huahua/start:test # 上面的一串数字是容器id 容器id 就是 打开 docker bash 后的主机名 最后一部分为目标镜像的仓库名和tag 名 通过dokerfile 生成镜像 使用 docker commit 来扩展一个镜像比较简单，但是不方便在一个团队中分享。我们可以使用 docker build 来创建一个新的镜像。为此，首先需要创建一个 Dockerfile，包含一些如何创建镜像的指令。 新建一个目录和一个Dockerfile:\n1 2 3 4 5 # This is a comment FROM node:latest MAINTAINER Vi.Ci\u0026lt;heyuhuade@gmail.com\u0026gt; RUN apt-get -qq curl RUN apt-get -qq babe-cli 编写完成 Dockerfile 后可以使用 docker build 来生成镜像。\n1 $ sudo docker build -t \u0026#34;huahua/start:v2\u0026#34; . 其中 ==-t== 标记来添加 tag，指定新的镜像的用户信息。 “.” 是 Dockerfile 所在的路径（当前目录），也可以 替换为一个具体的 Dockerfile 的路径。\nDockfile 中的指令被一条一条的执行。每一步都创建了一个新的容器，在 容器中执行指令并提交修改（就跟之前介绍过的 docker commit 一样）。当所有的指令都执行完毕之 后，返回了最终的镜像 id。所有的中间步骤所产生的容器都被删除和清理了。\n值得注意的是在dockerfile中的命令都必须避免io交互 例如:\n在ubuntu中 apt-get 要根据情况加上 ==-qq==(除了错误外什么都不输出 | linux哲学中有一条:什么都不提示就是最好的情况) 或者 ==-y==(对所有的询问回答yes) ##############################上面是入门笔记#################################\ndocker 项目部署 (按照官方文档进行安装)\n在安装后的一些必要操作 添加docker用户组 并将docker管理者添加到group中 sudo group add docker 添加docker用户组 sudo usermod -aG docker huahua 将花花添加到docker 组 sudo service docker restart 重启docker deamo 将docker 添加到开机自启动后退出root 4. sudo chkconfig docker on 5. 切换到 huahua 进行 无拘无束的docker操作 项目文件 存放在数据卷或着数据卷容器中 数据卷的添加 可以看做mount\n使用 -v 标记也可以指定挂载一个本地主机的目录到容器中去。\n1 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp 目录。这个功能在进行测试的时候十分方便，比如用户可以放置一些程序到本地目录中，来查看容器是否正常工作。本地目录的路径必须是绝对路径，如果目录不存在 Docker 会自动为你创建它。\n注意：Dockerfile 中不支持这种用法，这是因为 Dockerfile 是为了移植和分享用的。然而，不同操作系统的路径格式不一样，所以目前还不能支持。 Docker 挂载数据卷的默认权限是读写，用户也可以通过 :ro 指定为只读。\n1 2 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 加了 :ro 之后，就挂载为只读了。\n查看数据卷的具体信息\n在主机里使用以下命令可以查看指定容器的信息\n1 $ docker inspect web \u0026hellip;\n实验环节: 在app2上部署mongo replica arbiter(仲裁者) 从hub中下载合适的mongo镜像(version 3.0.1) 一定要使用阿里提供的加速服务,否则慢的爆炸 1 docker pull mongo:3.0.1 在宿主机上创建mongo的数据目录及配置文件目录 并映射到容器\n数据目录 1 2 $ sudo mkdir -p /data/mongo_data/mongo_arbiter $ sudo chmod -R a+rw /data/mongo_data/ 生成上线仲裁者容器 日志目录绑定; db数据目录绑定; 端口绑定; 1 docker run --name ksx_arbiter -p 10.163.8.90:27099:27017 -v /data/mongo_data/mongo_arbiter:/data/db -d mongo:3.0.1 --replSet \u0026#34;ksxingrs1\u0026#34; --name 定义了容器名 -p 将内网ip的27099 端口映射到了docker中的mongodb端口 -v 必要的目录及文件映射 -d 建守护进程\n切换到 db1 服务器 -\u0026gt;添加arbiter节点 1 \u0026gt; rs.addArb(\u0026#39;10.163.8.90:27099\u0026#39;) 返回app2 进入 ksx_arbiter -\u0026gt; 查看 mongo状态 1 docker exec -it ksx_arbiter /bin/bash 如果有错误 查看docker 日志信息 1 sudo journalctl -u docker \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; 全文完 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\n某部署版方案简略(请略过) mongo docker 快速部署\n配置文件目录 1 2 $ sudo mkdir /data/mongo_data/mongo_conf 日志目录 1 $ sudo mkdir /data/mongo_data/mongo_log 使用配置(上传到了公司知识库) 1 2 3 4 5 6 7 8 9 10 11 12 $ sudo vi /data/mongo_data/mongo_conf/mongo.conf systemLog: destination: file path: \u0026#34;/data/mongo_data/mongo_log/mongodb.log\u0026#34; logAppend: true storage: journal: enabled: true processManagement: fork: true mysql 版本:5.6.31\nmecache\nnginx 目前使用的nginx 版本为 1.6.2\npython 环境 flask\n","date":"2016-11-28T19:48:21Z","permalink":"http://blog.heyuhua.com/p/docker-%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","title":"docker 入门笔记"},{"content":"我有一身绝佳的溜门撬锁技巧\n环境 host: win10 ip:192.168.223.102 with shadowsocks 服务端口 1080 guest: centos7(vm虚拟机) ip:192.168.223.118 桥接网络。。。。。。。。。。。 如果是nat转发，则可以把下文的代理地址替换为host的nat网关ip 类似 10.0.15.1\n问题 host 已经配置sock5 代理 在 1080 端口，如何让guest虚拟机能够使用host代理？\n方案 方案1 \u0026mdash; proxychains 1 2 3 4 5 6 7 8 9 10 11 12 13 14 yum install gcc wget --no-check-certificate https://github.com/pypa/pip/archive/1.5.5.tar.gz tar zvxf 1.5.5.tar.gz #解压文件 cd pip-1.5.5/ python setup.py install yum install -y git cd /opt git clone https://github.com/haad/proxychains cd proxychains/ ./configure --sysconfdir=/usr/local/etc make \u0026amp;amp;\u0026amp;amp; make install 配置文件位于 /opt/proxychains/src/proxychains.conf 需要拷贝 cp /opt/proxychains/src/proxychains.conf /etc/proxychains.conf 配置: 在上述文件末尾修改 代理配置 （eg: socks5 192.168.223.2 1080）\n调用方法: proxychains4 + 命令\n方案2 \u0026mdash; 添加环境变量代理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 vi ~/.bash_profile # or .bashrc or .zshrc # 末尾添加如下内容 export http_proxy=http://192.168.223.102:1080/ # host的shadowsocks服务支持http # 如果使用代理的环境复杂还可以按需添加如下变量 export https_proxy=$http_proxy # export ftp_proxy=$http_proxy # 内网常用ftp时最好不要加,有大坑 export rsync_proxy=$http_proxy # 不懂 export no_proxy=\u0026#34;localhost,127.0.0.1,localaddress,.localdomain.com\u0026#34; # 不需要代理的东东 # 退出 vi # 使应用生效(若不生效则重启shell 或者注销当前用户 或 sudo reboot) source ~/.bash_profile # 参见第一行 ","date":"2016-11-28T17:43:37Z","permalink":"http://blog.heyuhua.com/p/%E4%BD%BF%E7%94%A8%E5%86%85%E7%BD%91%E7%8E%AF%E5%A2%83%E4%B8%8B%E7%9A%84%E4%BB%A3%E7%90%86%E8%AE%A8%E8%AE%BA/","title":"使用内网环境下的代理讨论"},{"content":"禅师寻一鸡，系绳于其足。拉绳，鸡倒而复起，如此有八。吾问：汝教我锲而不舍？答曰：No, 拉鸡八倒。\n如果你是一个高端全栈工程师并且负责某产品的研发 写后端api就不要想着前端怎么调用方便 写前端就不要想后端怎么写方便 以上两条起码会保证你的接口足够的simple. 永远不要为了方便把任何model 放在view 模块 改队友的代码一定要给ticket 跪求某大神做review ###　接口设计尽量灵活 栗子： 如果有函数需要传入保存日志的地址\n1 2 3 4 5 6 7 8 import os def foo(*args, logpath=\u0026#39;.\u0026#39;): if os.path.isdir(logpath): # 从args 获取参数保存 pass else: # 尽量处理 不存在目录，相对路径 给定文件名（带后缀）的情况 pass 其他 exception 尽量不要输出变量内容 interface 设计的默认参数尽量不要设为null 或者其他无意义的值 跟大屌们一起工作的注意事项 工作在传统安全行业一线的工程师们都有些怪毛病，他们可能熟读linux kernel源码，精通windows 驱动，还有很多老罗（罗升阳）一样研究 Android 源码的苦行僧。但是对底层的过度熟悉会带来一些好玩的事情。\n写汇编c 出身的大哥们会质疑python解释器，如果它们让你们查错，记得想想python和c的区别 对面大哥甚至在python强行添加context级别的goto语法\nkeep your self.\n当你是一个team中developer的时候（于2017-11-30） 当好一颗螺丝钉\n","date":"2016-11-02T00:00:00Z","permalink":"http://blog.heyuhua.com/p/%E6%9F%90%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84%E5%B7%A5%E4%BD%9C%E7%BB%8F%E9%AA%8C%E6%80%BB%E7%BB%93/","title":"某工程师的工作（经验）总结"}]